{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import dash\n",
    "from dash.dependencies import Input, Output, State\n",
    "import dash_core_components as dcc\n",
    "import dash_html_components as html\n",
    "import dash_table_experiments as dt \n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "import math \n",
    "import pandas as pd\n",
    "report=pd.DataFrame({'creteria':['Accuracy','erreur I','erreurII' ,'AUC','CV ACU','AIC','som error']})\n",
    "import base64\n",
    "from sklearn import  metrics \n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import cross_validation\n",
    "import matplotlib.pylab as plt\n",
    "from sklearn.metrics import classification_report\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from loremipsum import get_sentences\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.ensemble import GradientBoostingClassifier  #GBM algorithm\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import plotly.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn import tree\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "import time \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## change the link   \n",
    "lien=\"C:/Users/DELL/Desktop/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * Running on http://127.0.0.1:8050/ (Press CTRL+C to quit)\n",
      "127.0.0.1 - - [04/Sep/2018 20:11:22] \"GET / HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [04/Sep/2018 20:11:22] \"GET /_dash-component-suites/dash_renderer/react@15.4.2.min.js?v=0.12.1 HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [04/Sep/2018 20:11:22] \"GET /_dash-component-suites/dash_renderer/react-dom@15.4.2.min.js?v=0.12.1 HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [04/Sep/2018 20:11:22] \"GET /_dash-component-suites/dash_html_components/bundle.js?v=0.10.0 HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [04/Sep/2018 20:11:23] \"GET /_dash-component-suites/dash_core_components/plotly-1.31.0.min.js?v=0.15.0rc1 HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [04/Sep/2018 20:11:23] \"GET /_dash-component-suites/dash_core_components/bundle.js?v=0.15.0rc1 HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [04/Sep/2018 20:11:23] \"GET /_dash-component-suites/dash_table_experiments/bundle.js?v=0.6.0 HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [04/Sep/2018 20:11:23] \"GET /_dash-component-suites/dash_renderer/bundle.js?v=0.12.1 HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [04/Sep/2018 20:11:25] \"GET /_dash-layout HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [04/Sep/2018 20:11:25] \"GET /_dash-dependencies HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [04/Sep/2018 20:11:25] \"POST /_dash-update-component HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [04/Sep/2018 20:11:25] \"POST /_dash-update-component HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [04/Sep/2018 20:11:25] \"POST /_dash-update-component HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [04/Sep/2018 20:11:25] \"POST /_dash-update-component HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [04/Sep/2018 20:11:25] \"POST /_dash-update-component HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contenant is none !\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [04/Sep/2018 20:11:26] \"POST /_dash-update-component HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [04/Sep/2018 20:11:26] \"POST /_dash-update-component HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [04/Sep/2018 20:11:26] \"POST /_dash-update-component HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [04/Sep/2018 20:11:26] \"POST /_dash-update-component HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "updating... dff empty?: True\n",
      "updating... dff empty?: True\n",
      "updating... dff empty?: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [04/Sep/2018 20:11:27] \"POST /_dash-update-component HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [04/Sep/2018 20:11:27] \"POST /_dash-update-component HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [04/Sep/2018 20:11:27] \"POST /_dash-update-component HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [04/Sep/2018 20:11:27] \"POST /_dash-update-component HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [04/Sep/2018 20:11:27] \"POST /_dash-update-component HTTP/1.1\" 200 -\n",
      "[2018-09-04 20:11:27,602] ERROR in app: Exception on /_dash-update-component [POST]\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\DELL\\Anaconda3\\lib\\site-packages\\flask\\app.py\", line 1982, in wsgi_app\n",
      "    response = self.full_dispatch_request()\n",
      "  File \"C:\\Users\\DELL\\Anaconda3\\lib\\site-packages\\flask\\app.py\", line 1614, in full_dispatch_request\n",
      "    rv = self.handle_user_exception(e)\n",
      "  File \"C:\\Users\\DELL\\Anaconda3\\lib\\site-packages\\flask\\app.py\", line 1517, in handle_user_exception\n",
      "    reraise(exc_type, exc_value, tb)\n",
      "  File \"C:\\Users\\DELL\\Anaconda3\\lib\\site-packages\\flask\\_compat.py\", line 33, in reraise\n",
      "    raise value\n",
      "  File \"C:\\Users\\DELL\\Anaconda3\\lib\\site-packages\\flask\\app.py\", line 1612, in full_dispatch_request\n",
      "    rv = self.dispatch_request()\n",
      "  File \"C:\\Users\\DELL\\Anaconda3\\lib\\site-packages\\flask\\app.py\", line 1598, in dispatch_request\n",
      "    return self.view_functions[rule.endpoint](**req.view_args)\n",
      "  File \"C:\\Users\\DELL\\Anaconda3\\lib\\site-packages\\dash\\dash.py\", line 556, in dispatch\n",
      "    return self.callback_map[target_id]['callback'](*args)\n",
      "  File \"C:\\Users\\DELL\\Anaconda3\\lib\\site-packages\\dash\\dash.py\", line 513, in add_context\n",
      "    output_value = func(*args, **kwargs)\n",
      "  File \"<ipython-input-8-9c61f5720616>\", line 1642, in downloadTbale\n",
      "    table.to_csv(fileName, sep=';', encoding='utf-8')\n",
      "  File \"C:\\Users\\DELL\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\", line 1403, in to_csv\n",
      "    formatter.save()\n",
      "  File \"C:\\Users\\DELL\\Anaconda3\\lib\\site-packages\\pandas\\io\\formats\\format.py\", line 1577, in save\n",
      "    compression=self.compression)\n",
      "  File \"C:\\Users\\DELL\\Anaconda3\\lib\\site-packages\\pandas\\io\\common.py\", line 382, in _get_handle\n",
      "    f = open(path_or_buf, mode, encoding=encoding)\n",
      "FileNotFoundError: [Errno 2] No such file or directory: 'None/predict.csv'\n",
      "127.0.0.1 - - [04/Sep/2018 20:11:27] \"POST /_dash-update-component HTTP/1.1\" 500 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "csv uploaded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [04/Sep/2018 20:11:40] \"POST /_dash-update-component HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "csv uploaded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [04/Sep/2018 20:11:40] \"POST /_dash-update-component HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "csv uploaded\n",
      "data ulloded  successflly\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [04/Sep/2018 20:11:43] \"POST /_dash-update-component HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "csv uploaded\n",
      "data ulloded  successflly\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [04/Sep/2018 20:11:46] \"POST /_dash-update-component HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [04/Sep/2018 20:11:50] \"POST /_dash-update-component HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "updating... dff empty?: False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [04/Sep/2018 20:11:51] \"POST /_dash-update-component HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "updating... dff empty?: False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [04/Sep/2018 20:11:51] \"POST /_dash-update-component HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [04/Sep/2018 20:11:52] \"POST /_dash-update-component HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [04/Sep/2018 20:11:52] \"POST /_dash-update-component HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "updating... dff empty?: False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [04/Sep/2018 20:11:54] \"POST /_dash-update-component HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [04/Sep/2018 20:11:54] \"POST /_dash-update-component HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [04/Sep/2018 20:11:55] \"POST /_dash-update-component HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [04/Sep/2018 20:11:56] \"POST /_dash-update-component HTTP/1.1\" 200 -\n",
      "[2018-09-04 20:11:56,486] ERROR in app: Exception on /_dash-update-component [POST]\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\DELL\\Anaconda3\\lib\\site-packages\\flask\\app.py\", line 1982, in wsgi_app\n",
      "    response = self.full_dispatch_request()\n",
      "  File \"C:\\Users\\DELL\\Anaconda3\\lib\\site-packages\\flask\\app.py\", line 1614, in full_dispatch_request\n",
      "    rv = self.handle_user_exception(e)\n",
      "  File \"C:\\Users\\DELL\\Anaconda3\\lib\\site-packages\\flask\\app.py\", line 1517, in handle_user_exception\n",
      "    reraise(exc_type, exc_value, tb)\n",
      "  File \"C:\\Users\\DELL\\Anaconda3\\lib\\site-packages\\flask\\_compat.py\", line 33, in reraise\n",
      "    raise value\n",
      "  File \"C:\\Users\\DELL\\Anaconda3\\lib\\site-packages\\flask\\app.py\", line 1612, in full_dispatch_request\n",
      "    rv = self.dispatch_request()\n",
      "  File \"C:\\Users\\DELL\\Anaconda3\\lib\\site-packages\\flask\\app.py\", line 1598, in dispatch_request\n",
      "    return self.view_functions[rule.endpoint](**req.view_args)\n",
      "  File \"C:\\Users\\DELL\\Anaconda3\\lib\\site-packages\\dash\\dash.py\", line 556, in dispatch\n",
      "    return self.callback_map[target_id]['callback'](*args)\n",
      "  File \"C:\\Users\\DELL\\Anaconda3\\lib\\site-packages\\dash\\dash.py\", line 513, in add_context\n",
      "    output_value = func(*args, **kwargs)\n",
      "  File \"<ipython-input-8-9c61f5720616>\", line 1642, in downloadTbale\n",
      "    table.to_csv(fileName, sep=';', encoding='utf-8')\n",
      "  File \"C:\\Users\\DELL\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\", line 1403, in to_csv\n",
      "    formatter.save()\n",
      "  File \"C:\\Users\\DELL\\Anaconda3\\lib\\site-packages\\pandas\\io\\formats\\format.py\", line 1577, in save\n",
      "    compression=self.compression)\n",
      "  File \"C:\\Users\\DELL\\Anaconda3\\lib\\site-packages\\pandas\\io\\common.py\", line 382, in _get_handle\n",
      "    f = open(path_or_buf, mode, encoding=encoding)\n",
      "FileNotFoundError: [Errno 2] No such file or directory: 'None/predict.csv'\n",
      "127.0.0.1 - - [04/Sep/2018 20:11:56] \"POST /_dash-update-component HTTP/1.1\" 500 -\n",
      "127.0.0.1 - - [04/Sep/2018 20:11:58] \"POST /_dash-update-component HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [04/Sep/2018 20:11:59] \"POST /_dash-update-component HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [04/Sep/2018 20:12:00] \"POST /_dash-update-component HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [04/Sep/2018 20:12:00] \"POST /_dash-update-component HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [04/Sep/2018 20:12:01] \"POST /_dash-update-component HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [04/Sep/2018 20:12:01] \"POST /_dash-update-component HTTP/1.1\" 200 -\n",
      "[2018-09-04 20:12:01,964] ERROR in app: Exception on /_dash-update-component [POST]\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\DELL\\Anaconda3\\lib\\site-packages\\flask\\app.py\", line 1982, in wsgi_app\n",
      "    response = self.full_dispatch_request()\n",
      "  File \"C:\\Users\\DELL\\Anaconda3\\lib\\site-packages\\flask\\app.py\", line 1614, in full_dispatch_request\n",
      "    rv = self.handle_user_exception(e)\n",
      "  File \"C:\\Users\\DELL\\Anaconda3\\lib\\site-packages\\flask\\app.py\", line 1517, in handle_user_exception\n",
      "    reraise(exc_type, exc_value, tb)\n",
      "  File \"C:\\Users\\DELL\\Anaconda3\\lib\\site-packages\\flask\\_compat.py\", line 33, in reraise\n",
      "    raise value\n",
      "  File \"C:\\Users\\DELL\\Anaconda3\\lib\\site-packages\\flask\\app.py\", line 1612, in full_dispatch_request\n",
      "    rv = self.dispatch_request()\n",
      "  File \"C:\\Users\\DELL\\Anaconda3\\lib\\site-packages\\flask\\app.py\", line 1598, in dispatch_request\n",
      "    return self.view_functions[rule.endpoint](**req.view_args)\n",
      "  File \"C:\\Users\\DELL\\Anaconda3\\lib\\site-packages\\dash\\dash.py\", line 556, in dispatch\n",
      "    return self.callback_map[target_id]['callback'](*args)\n",
      "  File \"C:\\Users\\DELL\\Anaconda3\\lib\\site-packages\\dash\\dash.py\", line 513, in add_context\n",
      "    output_value = func(*args, **kwargs)\n",
      "  File \"<ipython-input-8-9c61f5720616>\", line 1642, in downloadTbale\n",
      "    table.to_csv(fileName, sep=';', encoding='utf-8')\n",
      "  File \"C:\\Users\\DELL\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\", line 1403, in to_csv\n",
      "    formatter.save()\n",
      "  File \"C:\\Users\\DELL\\Anaconda3\\lib\\site-packages\\pandas\\io\\formats\\format.py\", line 1577, in save\n",
      "    compression=self.compression)\n",
      "  File \"C:\\Users\\DELL\\Anaconda3\\lib\\site-packages\\pandas\\io\\common.py\", line 382, in _get_handle\n",
      "    f = open(path_or_buf, mode, encoding=encoding)\n",
      "FileNotFoundError: [Errno 2] No such file or directory: 'None/predict.csv'\n",
      "127.0.0.1 - - [04/Sep/2018 20:12:01] \"POST /_dash-update-component HTTP/1.1\" 500 -\n",
      "[2018-09-04 20:12:03,854] ERROR in app: Exception on /_dash-update-component [POST]\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\DELL\\Anaconda3\\lib\\site-packages\\flask\\app.py\", line 1982, in wsgi_app\n",
      "    response = self.full_dispatch_request()\n",
      "  File \"C:\\Users\\DELL\\Anaconda3\\lib\\site-packages\\flask\\app.py\", line 1614, in full_dispatch_request\n",
      "    rv = self.handle_user_exception(e)\n",
      "  File \"C:\\Users\\DELL\\Anaconda3\\lib\\site-packages\\flask\\app.py\", line 1517, in handle_user_exception\n",
      "    reraise(exc_type, exc_value, tb)\n",
      "  File \"C:\\Users\\DELL\\Anaconda3\\lib\\site-packages\\flask\\_compat.py\", line 33, in reraise\n",
      "    raise value\n",
      "  File \"C:\\Users\\DELL\\Anaconda3\\lib\\site-packages\\flask\\app.py\", line 1612, in full_dispatch_request\n",
      "    rv = self.dispatch_request()\n",
      "  File \"C:\\Users\\DELL\\Anaconda3\\lib\\site-packages\\flask\\app.py\", line 1598, in dispatch_request\n",
      "    return self.view_functions[rule.endpoint](**req.view_args)\n",
      "  File \"C:\\Users\\DELL\\Anaconda3\\lib\\site-packages\\dash\\dash.py\", line 556, in dispatch\n",
      "    return self.callback_map[target_id]['callback'](*args)\n",
      "  File \"C:\\Users\\DELL\\Anaconda3\\lib\\site-packages\\dash\\dash.py\", line 513, in add_context\n",
      "    output_value = func(*args, **kwargs)\n",
      "  File \"<ipython-input-8-9c61f5720616>\", line 606, in FeaturesSelection\n",
      "    x=df[xvar]\n",
      "  File \"C:\\Users\\DELL\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\", line 1964, in __getitem__\n",
      "    return self._getitem_column(key)\n",
      "  File \"C:\\Users\\DELL\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\", line 1971, in _getitem_column\n",
      "    return self._get_item_cache(key)\n",
      "  File \"C:\\Users\\DELL\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\", line 1645, in _get_item_cache\n",
      "    values = self._data.get(item)\n",
      "  File \"C:\\Users\\DELL\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals.py\", line 3599, in get\n",
      "    raise ValueError(\"cannot label index with a null key\")\n",
      "ValueError: cannot label index with a null key\n",
      "127.0.0.1 - - [04/Sep/2018 20:12:04] \"POST /_dash-update-component HTTP/1.1\" 500 -\n",
      "127.0.0.1 - - [04/Sep/2018 20:12:04] \"POST /_dash-update-component HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [04/Sep/2018 20:12:05] \"POST /_dash-update-component HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [04/Sep/2018 20:12:06] \"POST /_dash-update-component HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [04/Sep/2018 20:12:07] \"POST /_dash-update-component HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [04/Sep/2018 20:12:07] \"POST /_dash-update-component HTTP/1.1\" 200 -\n",
      "[2018-09-04 20:12:07,530] ERROR in app: Exception on /_dash-update-component [POST]\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\DELL\\Anaconda3\\lib\\site-packages\\flask\\app.py\", line 1982, in wsgi_app\n",
      "    response = self.full_dispatch_request()\n",
      "  File \"C:\\Users\\DELL\\Anaconda3\\lib\\site-packages\\flask\\app.py\", line 1614, in full_dispatch_request\n",
      "    rv = self.handle_user_exception(e)\n",
      "  File \"C:\\Users\\DELL\\Anaconda3\\lib\\site-packages\\flask\\app.py\", line 1517, in handle_user_exception\n",
      "    reraise(exc_type, exc_value, tb)\n",
      "  File \"C:\\Users\\DELL\\Anaconda3\\lib\\site-packages\\flask\\_compat.py\", line 33, in reraise\n",
      "    raise value\n",
      "  File \"C:\\Users\\DELL\\Anaconda3\\lib\\site-packages\\flask\\app.py\", line 1612, in full_dispatch_request\n",
      "    rv = self.dispatch_request()\n",
      "  File \"C:\\Users\\DELL\\Anaconda3\\lib\\site-packages\\flask\\app.py\", line 1598, in dispatch_request\n",
      "    return self.view_functions[rule.endpoint](**req.view_args)\n",
      "  File \"C:\\Users\\DELL\\Anaconda3\\lib\\site-packages\\dash\\dash.py\", line 556, in dispatch\n",
      "    return self.callback_map[target_id]['callback'](*args)\n",
      "  File \"C:\\Users\\DELL\\Anaconda3\\lib\\site-packages\\dash\\dash.py\", line 513, in add_context\n",
      "    output_value = func(*args, **kwargs)\n",
      "  File \"<ipython-input-8-9c61f5720616>\", line 1642, in downloadTbale\n",
      "    table.to_csv(fileName, sep=';', encoding='utf-8')\n",
      "  File \"C:\\Users\\DELL\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\", line 1403, in to_csv\n",
      "    formatter.save()\n",
      "  File \"C:\\Users\\DELL\\Anaconda3\\lib\\site-packages\\pandas\\io\\formats\\format.py\", line 1577, in save\n",
      "    compression=self.compression)\n",
      "  File \"C:\\Users\\DELL\\Anaconda3\\lib\\site-packages\\pandas\\io\\common.py\", line 382, in _get_handle\n",
      "    f = open(path_or_buf, mode, encoding=encoding)\n",
      "FileNotFoundError: [Errno 2] No such file or directory: 'None/predict.csv'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [04/Sep/2018 20:12:07] \"POST /_dash-update-component HTTP/1.1\" 500 -\n",
      "[2018-09-04 20:12:20,420] ERROR in app: Exception on /_dash-update-component [POST]\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\DELL\\Anaconda3\\lib\\site-packages\\flask\\app.py\", line 1982, in wsgi_app\n",
      "    response = self.full_dispatch_request()\n",
      "  File \"C:\\Users\\DELL\\Anaconda3\\lib\\site-packages\\flask\\app.py\", line 1614, in full_dispatch_request\n",
      "    rv = self.handle_user_exception(e)\n",
      "  File \"C:\\Users\\DELL\\Anaconda3\\lib\\site-packages\\flask\\app.py\", line 1517, in handle_user_exception\n",
      "    reraise(exc_type, exc_value, tb)\n",
      "  File \"C:\\Users\\DELL\\Anaconda3\\lib\\site-packages\\flask\\_compat.py\", line 33, in reraise\n",
      "    raise value\n",
      "  File \"C:\\Users\\DELL\\Anaconda3\\lib\\site-packages\\flask\\app.py\", line 1612, in full_dispatch_request\n",
      "    rv = self.dispatch_request()\n",
      "  File \"C:\\Users\\DELL\\Anaconda3\\lib\\site-packages\\flask\\app.py\", line 1598, in dispatch_request\n",
      "    return self.view_functions[rule.endpoint](**req.view_args)\n",
      "  File \"C:\\Users\\DELL\\Anaconda3\\lib\\site-packages\\dash\\dash.py\", line 556, in dispatch\n",
      "    return self.callback_map[target_id]['callback'](*args)\n",
      "  File \"C:\\Users\\DELL\\Anaconda3\\lib\\site-packages\\dash\\dash.py\", line 513, in add_context\n",
      "    output_value = func(*args, **kwargs)\n",
      "  File \"<ipython-input-8-9c61f5720616>\", line 606, in FeaturesSelection\n",
      "    x=df[xvar]\n",
      "  File \"C:\\Users\\DELL\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\", line 1964, in __getitem__\n",
      "    return self._getitem_column(key)\n",
      "  File \"C:\\Users\\DELL\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\", line 1971, in _getitem_column\n",
      "    return self._get_item_cache(key)\n",
      "  File \"C:\\Users\\DELL\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\", line 1645, in _get_item_cache\n",
      "    values = self._data.get(item)\n",
      "  File \"C:\\Users\\DELL\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals.py\", line 3599, in get\n",
      "    raise ValueError(\"cannot label index with a null key\")\n",
      "ValueError: cannot label index with a null key\n",
      "127.0.0.1 - - [04/Sep/2018 20:12:20] \"POST /_dash-update-component HTTP/1.1\" 500 -\n",
      "[2018-09-04 20:12:29,228] ERROR in app: Exception on /_dash-update-component [POST]\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\DELL\\Anaconda3\\lib\\site-packages\\flask\\app.py\", line 1982, in wsgi_app\n",
      "    response = self.full_dispatch_request()\n",
      "  File \"C:\\Users\\DELL\\Anaconda3\\lib\\site-packages\\flask\\app.py\", line 1614, in full_dispatch_request\n",
      "    rv = self.handle_user_exception(e)\n",
      "  File \"C:\\Users\\DELL\\Anaconda3\\lib\\site-packages\\flask\\app.py\", line 1517, in handle_user_exception\n",
      "    reraise(exc_type, exc_value, tb)\n",
      "  File \"C:\\Users\\DELL\\Anaconda3\\lib\\site-packages\\flask\\_compat.py\", line 33, in reraise\n",
      "    raise value\n",
      "  File \"C:\\Users\\DELL\\Anaconda3\\lib\\site-packages\\flask\\app.py\", line 1612, in full_dispatch_request\n",
      "    rv = self.dispatch_request()\n",
      "  File \"C:\\Users\\DELL\\Anaconda3\\lib\\site-packages\\flask\\app.py\", line 1598, in dispatch_request\n",
      "    return self.view_functions[rule.endpoint](**req.view_args)\n",
      "  File \"C:\\Users\\DELL\\Anaconda3\\lib\\site-packages\\dash\\dash.py\", line 556, in dispatch\n",
      "    return self.callback_map[target_id]['callback'](*args)\n",
      "  File \"C:\\Users\\DELL\\Anaconda3\\lib\\site-packages\\dash\\dash.py\", line 513, in add_context\n",
      "    output_value = func(*args, **kwargs)\n",
      "  File \"<ipython-input-8-9c61f5720616>\", line 606, in FeaturesSelection\n",
      "    x=df[xvar]\n",
      "  File \"C:\\Users\\DELL\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\", line 1964, in __getitem__\n",
      "    return self._getitem_column(key)\n",
      "  File \"C:\\Users\\DELL\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\", line 1971, in _getitem_column\n",
      "    return self._get_item_cache(key)\n",
      "  File \"C:\\Users\\DELL\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\", line 1645, in _get_item_cache\n",
      "    values = self._data.get(item)\n",
      "  File \"C:\\Users\\DELL\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals.py\", line 3599, in get\n",
      "    raise ValueError(\"cannot label index with a null key\")\n",
      "ValueError: cannot label index with a null key\n",
      "127.0.0.1 - - [04/Sep/2018 20:12:29] \"POST /_dash-update-component HTTP/1.1\" 500 -\n",
      "[2018-09-04 20:12:34,658] ERROR in app: Exception on /_dash-update-component [POST]\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\DELL\\Anaconda3\\lib\\site-packages\\flask\\app.py\", line 1982, in wsgi_app\n",
      "    response = self.full_dispatch_request()\n",
      "  File \"C:\\Users\\DELL\\Anaconda3\\lib\\site-packages\\flask\\app.py\", line 1614, in full_dispatch_request\n",
      "    rv = self.handle_user_exception(e)\n",
      "  File \"C:\\Users\\DELL\\Anaconda3\\lib\\site-packages\\flask\\app.py\", line 1517, in handle_user_exception\n",
      "    reraise(exc_type, exc_value, tb)\n",
      "  File \"C:\\Users\\DELL\\Anaconda3\\lib\\site-packages\\flask\\_compat.py\", line 33, in reraise\n",
      "    raise value\n",
      "  File \"C:\\Users\\DELL\\Anaconda3\\lib\\site-packages\\flask\\app.py\", line 1612, in full_dispatch_request\n",
      "    rv = self.dispatch_request()\n",
      "  File \"C:\\Users\\DELL\\Anaconda3\\lib\\site-packages\\flask\\app.py\", line 1598, in dispatch_request\n",
      "    return self.view_functions[rule.endpoint](**req.view_args)\n",
      "  File \"C:\\Users\\DELL\\Anaconda3\\lib\\site-packages\\dash\\dash.py\", line 556, in dispatch\n",
      "    return self.callback_map[target_id]['callback'](*args)\n",
      "  File \"C:\\Users\\DELL\\Anaconda3\\lib\\site-packages\\dash\\dash.py\", line 513, in add_context\n",
      "    output_value = func(*args, **kwargs)\n",
      "  File \"<ipython-input-8-9c61f5720616>\", line 606, in FeaturesSelection\n",
      "    x=df[xvar]\n",
      "  File \"C:\\Users\\DELL\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\", line 1964, in __getitem__\n",
      "    return self._getitem_column(key)\n",
      "  File \"C:\\Users\\DELL\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\", line 1971, in _getitem_column\n",
      "    return self._get_item_cache(key)\n",
      "  File \"C:\\Users\\DELL\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\", line 1645, in _get_item_cache\n",
      "    values = self._data.get(item)\n",
      "  File \"C:\\Users\\DELL\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals.py\", line 3599, in get\n",
      "    raise ValueError(\"cannot label index with a null key\")\n",
      "ValueError: cannot label index with a null key\n",
      "127.0.0.1 - - [04/Sep/2018 20:12:34] \"POST /_dash-update-component HTTP/1.1\" 500 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "selected all var for featres selection \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [04/Sep/2018 20:12:47] \"POST /_dash-update-component HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "selected all var for featres selection \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [04/Sep/2018 20:12:51] \"POST /_dash-update-component HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [04/Sep/2018 20:12:51] \"POST /_dash-update-component HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [04/Sep/2018 20:12:52] \"POST /_dash-update-component HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [04/Sep/2018 20:12:52] \"POST /_dash-update-component HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [04/Sep/2018 20:12:52] \"POST /_dash-update-component HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [04/Sep/2018 20:12:52] \"POST /_dash-update-component HTTP/1.1\" 200 -\n",
      "[2018-09-04 20:12:53,008] ERROR in app: Exception on /_dash-update-component [POST]\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\DELL\\Anaconda3\\lib\\site-packages\\flask\\app.py\", line 1982, in wsgi_app\n",
      "    response = self.full_dispatch_request()\n",
      "  File \"C:\\Users\\DELL\\Anaconda3\\lib\\site-packages\\flask\\app.py\", line 1614, in full_dispatch_request\n",
      "    rv = self.handle_user_exception(e)\n",
      "  File \"C:\\Users\\DELL\\Anaconda3\\lib\\site-packages\\flask\\app.py\", line 1517, in handle_user_exception\n",
      "    reraise(exc_type, exc_value, tb)\n",
      "  File \"C:\\Users\\DELL\\Anaconda3\\lib\\site-packages\\flask\\_compat.py\", line 33, in reraise\n",
      "    raise value\n",
      "  File \"C:\\Users\\DELL\\Anaconda3\\lib\\site-packages\\flask\\app.py\", line 1612, in full_dispatch_request\n",
      "    rv = self.dispatch_request()\n",
      "  File \"C:\\Users\\DELL\\Anaconda3\\lib\\site-packages\\flask\\app.py\", line 1598, in dispatch_request\n",
      "    return self.view_functions[rule.endpoint](**req.view_args)\n",
      "  File \"C:\\Users\\DELL\\Anaconda3\\lib\\site-packages\\dash\\dash.py\", line 556, in dispatch\n",
      "    return self.callback_map[target_id]['callback'](*args)\n",
      "  File \"C:\\Users\\DELL\\Anaconda3\\lib\\site-packages\\dash\\dash.py\", line 513, in add_context\n",
      "    output_value = func(*args, **kwargs)\n",
      "  File \"<ipython-input-8-9c61f5720616>\", line 1642, in downloadTbale\n",
      "    table.to_csv(fileName, sep=';', encoding='utf-8')\n",
      "  File \"C:\\Users\\DELL\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\", line 1403, in to_csv\n",
      "    formatter.save()\n",
      "  File \"C:\\Users\\DELL\\Anaconda3\\lib\\site-packages\\pandas\\io\\formats\\format.py\", line 1577, in save\n",
      "    compression=self.compression)\n",
      "  File \"C:\\Users\\DELL\\Anaconda3\\lib\\site-packages\\pandas\\io\\common.py\", line 382, in _get_handle\n",
      "    f = open(path_or_buf, mode, encoding=encoding)\n",
      "FileNotFoundError: [Errno 2] No such file or directory: 'None/predict.csv'\n",
      "127.0.0.1 - - [04/Sep/2018 20:12:53] \"POST /_dash-update-component HTTP/1.1\" 500 -\n",
      "127.0.0.1 - - [04/Sep/2018 20:13:00] \"POST /_dash-update-component HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [04/Sep/2018 20:13:01] \"POST /_dash-update-component HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [04/Sep/2018 20:13:02] \"POST /_dash-update-component HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [04/Sep/2018 20:13:03] \"POST /_dash-update-component HTTP/1.1\" 200 -\n",
      "[2018-09-04 20:13:03,140] ERROR in app: Exception on /_dash-update-component [POST]\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\DELL\\Anaconda3\\lib\\site-packages\\flask\\app.py\", line 1982, in wsgi_app\n",
      "    response = self.full_dispatch_request()\n",
      "  File \"C:\\Users\\DELL\\Anaconda3\\lib\\site-packages\\flask\\app.py\", line 1614, in full_dispatch_request\n",
      "    rv = self.handle_user_exception(e)\n",
      "  File \"C:\\Users\\DELL\\Anaconda3\\lib\\site-packages\\flask\\app.py\", line 1517, in handle_user_exception\n",
      "    reraise(exc_type, exc_value, tb)\n",
      "  File \"C:\\Users\\DELL\\Anaconda3\\lib\\site-packages\\flask\\_compat.py\", line 33, in reraise\n",
      "    raise value\n",
      "  File \"C:\\Users\\DELL\\Anaconda3\\lib\\site-packages\\flask\\app.py\", line 1612, in full_dispatch_request\n",
      "    rv = self.dispatch_request()\n",
      "  File \"C:\\Users\\DELL\\Anaconda3\\lib\\site-packages\\flask\\app.py\", line 1598, in dispatch_request\n",
      "    return self.view_functions[rule.endpoint](**req.view_args)\n",
      "  File \"C:\\Users\\DELL\\Anaconda3\\lib\\site-packages\\dash\\dash.py\", line 556, in dispatch\n",
      "    return self.callback_map[target_id]['callback'](*args)\n",
      "  File \"C:\\Users\\DELL\\Anaconda3\\lib\\site-packages\\dash\\dash.py\", line 513, in add_context\n",
      "    output_value = func(*args, **kwargs)\n",
      "  File \"<ipython-input-8-9c61f5720616>\", line 1642, in downloadTbale\n",
      "    table.to_csv(fileName, sep=';', encoding='utf-8')\n",
      "  File \"C:\\Users\\DELL\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\", line 1403, in to_csv\n",
      "    formatter.save()\n",
      "  File \"C:\\Users\\DELL\\Anaconda3\\lib\\site-packages\\pandas\\io\\formats\\format.py\", line 1577, in save\n",
      "    compression=self.compression)\n",
      "  File \"C:\\Users\\DELL\\Anaconda3\\lib\\site-packages\\pandas\\io\\common.py\", line 382, in _get_handle\n",
      "    f = open(path_or_buf, mode, encoding=encoding)\n",
      "FileNotFoundError: [Errno 2] No such file or directory: 'None/predict.csv'\n",
      "127.0.0.1 - - [04/Sep/2018 20:13:03] \"POST /_dash-update-component HTTP/1.1\" 500 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "you choosed to work with selected features\n",
      "corr deleted var loaded successfully\n",
      "mlp done for model report\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [04/Sep/2018 20:13:12] \"POST /_dash-update-component HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Report done successflly\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [04/Sep/2018 20:13:17] \"POST /_dash-update-component HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "you choosed to work with selected features\n",
      "corr deleted var loaded successfully\n",
      "mlp model loaded for plot\n",
      "plot done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [04/Sep/2018 20:13:20] \"POST /_dash-update-component HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "you choosed to work with selected features\n",
      "corr deleted var loaded successfully\n",
      "confusion martix mlp done\n",
      "  MLPerceptron  predicted 0  predicted 1\n",
      "0     actuel 0         1204          124\n",
      "1     actuel 1          293          179\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [04/Sep/2018 20:13:31] \"POST /_dash-update-component HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [04/Sep/2018 20:13:33] \"POST /_dash-update-component HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "you choosed to work with selected features\n",
      "corr deleted var loaded successfully\n",
      "gbm model loaded for plot\n",
      "plot done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [04/Sep/2018 20:13:34] \"POST /_dash-update-component HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "you choosed to work with selected features\n",
      "corr deleted var loaded successfully\n",
      "confusion martix gbm done\n",
      "  Gradient Boosting  predicted 0  predicted 1\n",
      "0          actuel 0         1218          110\n",
      "1          actuel 1          288          184\n",
      "you choosed to work with selected features\n",
      "corr deleted var loaded successfully\n",
      "classification with GBM done successfully\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [04/Sep/2018 20:13:36] \"POST /_dash-update-component HTTP/1.1\" 200 -\n",
      "[2018-09-04 20:13:36,599] ERROR in app: Exception on /_dash-update-component [POST]\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\DELL\\Anaconda3\\lib\\site-packages\\flask\\app.py\", line 1982, in wsgi_app\n",
      "    response = self.full_dispatch_request()\n",
      "  File \"C:\\Users\\DELL\\Anaconda3\\lib\\site-packages\\flask\\app.py\", line 1614, in full_dispatch_request\n",
      "    rv = self.handle_user_exception(e)\n",
      "  File \"C:\\Users\\DELL\\Anaconda3\\lib\\site-packages\\flask\\app.py\", line 1517, in handle_user_exception\n",
      "    reraise(exc_type, exc_value, tb)\n",
      "  File \"C:\\Users\\DELL\\Anaconda3\\lib\\site-packages\\flask\\_compat.py\", line 33, in reraise\n",
      "    raise value\n",
      "  File \"C:\\Users\\DELL\\Anaconda3\\lib\\site-packages\\flask\\app.py\", line 1612, in full_dispatch_request\n",
      "    rv = self.dispatch_request()\n",
      "  File \"C:\\Users\\DELL\\Anaconda3\\lib\\site-packages\\flask\\app.py\", line 1598, in dispatch_request\n",
      "    return self.view_functions[rule.endpoint](**req.view_args)\n",
      "  File \"C:\\Users\\DELL\\Anaconda3\\lib\\site-packages\\dash\\dash.py\", line 556, in dispatch\n",
      "    return self.callback_map[target_id]['callback'](*args)\n",
      "  File \"C:\\Users\\DELL\\Anaconda3\\lib\\site-packages\\dash\\dash.py\", line 513, in add_context\n",
      "    output_value = func(*args, **kwargs)\n",
      "  File \"<ipython-input-8-9c61f5720616>\", line 1642, in downloadTbale\n",
      "    table.to_csv(fileName, sep=';', encoding='utf-8')\n",
      "  File \"C:\\Users\\DELL\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\", line 1403, in to_csv\n",
      "    formatter.save()\n",
      "  File \"C:\\Users\\DELL\\Anaconda3\\lib\\site-packages\\pandas\\io\\formats\\format.py\", line 1577, in save\n",
      "    compression=self.compression)\n",
      "  File \"C:\\Users\\DELL\\Anaconda3\\lib\\site-packages\\pandas\\io\\common.py\", line 382, in _get_handle\n",
      "    f = open(path_or_buf, mode, encoding=encoding)\n",
      "FileNotFoundError: [Errno 2] No such file or directory: 'None/predict.csv'\n",
      "127.0.0.1 - - [04/Sep/2018 20:13:36] \"POST /_dash-update-component HTTP/1.1\" 500 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Report done successflly\n",
      "you choosed to work with selected features\n",
      "corr deleted var loaded successfully\n",
      "classification with GBM done successfully\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [04/Sep/2018 20:13:39] \"POST /_dash-update-component HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Report done successflly\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [04/Sep/2018 20:13:50] \"POST /_dash-update-component HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compare table gbm done \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [04/Sep/2018 20:13:51] \"POST /_dash-update-component HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " gbm loaded model  for multi  plot\n",
      " multi plot done\n"
     ]
    }
   ],
   "source": [
    "\n",
    "app = dash.Dash()\n",
    "app.css.append_css({\n",
    "    \"external_url\": \"https://codepen.io/chriddyp/pen/bWLwgP.css\"\n",
    "})\n",
    "app.scripts.config.serve_locally=True\n",
    "colors = {\n",
    "    'background': '#f2f3f4',\n",
    "    'text': '#ee0c35'\n",
    "}\n",
    "\n",
    "app.layout = html.Div(style={'backgroundColor': colors['background']},\n",
    "    children=[\n",
    "    html.H1(\n",
    "        children='Ooreedoo',\n",
    "        style={\n",
    "                'textAlign': 'center',\n",
    "                'color': colors['text']\n",
    "            }\n",
    "    ),\n",
    "    html.Img(src=lien+'ooredoo.png'),\n",
    "\n",
    "    html.Div(children='Dash: A web application framework for Machine Learning .',\n",
    "             style={\n",
    "            'textAlign': 'center',\n",
    "            'color': colors['text']}\n",
    "        ),\n",
    "        html.H5(\"Upload Files\"),\n",
    "        dcc.Upload(\n",
    "            id='upload-data',\n",
    "            children=html.Div([\n",
    "                'Drag and Drop or ',\n",
    "                html.A('Select Files')\n",
    "            ]),\n",
    "            style={\n",
    "                'width': '100%',\n",
    "                'height': '60px',\n",
    "                'lineHeight': '60px',\n",
    "                'borderWidth': '1px',\n",
    "                'borderStyle': 'dashed',\n",
    "                'borderRadius': '5px',\n",
    "                'textAlign': 'center',\n",
    "                'margin': '10px',\n",
    "                'position': 'static',\n",
    "                'top': '120px', 'left': '20%',\n",
    "                'backgroundColor': '#ccffff'\n",
    "            },\n",
    "            multiple=False),\n",
    "#################################################################################################################        \n",
    "###### Data Explore\n",
    "        \n",
    "        html.Div([html.H4(\"Data Explore\") ],\n",
    "                 style={'textAlign': 'center',\n",
    "                        'fontSize':'25px',\n",
    "                        'textAlign': 'center',\n",
    "                        'color': colors['text']\n",
    "                       }\n",
    "                ),\n",
    "        html.Div([\n",
    "            html.Div([\n",
    "                html.H5(\"Uploaded Data\"),\n",
    "                html.Div(dt.DataTable(rows=[{}], id='table',row_selectable=True, filterable=True,\n",
    "                sortable=True,)),\n",
    "            ],className=\"six columns\"),\n",
    "            \n",
    "            html.Div([\n",
    "                html.H5('Data Summary'), \n",
    "                html.Div(dt.DataTable(rows=[{}], id='summary',row_selectable=True, filterable=True,\n",
    "                sortable=True, row_height=30,)),\n",
    "            ],className=\"six columns\"),\n",
    "            \n",
    "            ],className=\"row\",\n",
    "            style={\n",
    "                'width': '80%',\n",
    "                'borderStyle': 'solid',\n",
    "                'borderRadius': '5px',\n",
    "                'borderColor': '#e1e1d0',\n",
    "                'backgroundColor' : '#e6f0ff',\n",
    "                'position': 'static',\n",
    "                'marginLeft': 'auto',\n",
    "                'marginRight': 'auto',\n",
    "                'left': 0,\n",
    "                'right': 0\n",
    "            }\n",
    "        ),\n",
    "#################################################################################################################        \n",
    "#### select  columns \n",
    "        \n",
    "        html.Br(),\n",
    "        html.Div([html.H4(\"Select columns\") ],\n",
    "                 style={'textAlign': 'center',\n",
    "                        'fontSize':'25px',\n",
    "                        'textAlign': 'center',\n",
    "                        'color': colors['text']\n",
    "                       }\n",
    "                ),\n",
    "        html.Div(\n",
    "\n",
    "            [\n",
    "                 html.Div([\n",
    "                     html.Div([\n",
    "                         html.H6(\"Select predictive feature\"),\n",
    "                         dcc.Dropdown(id='dropdownY',multi = False, \n",
    "                                       placeholder='Select dependant var'), \n",
    "                         html.Div('Note: depente variable will be removed automaticly '),\n",
    "                         html.Br(),\n",
    "                         html.H6(\"Select id sbscriber's feature\"),        \n",
    "                          dcc.Dropdown(id='subs',\n",
    "                                       multi = False,\n",
    "                                       placeholder='Select subscriber var'), \n",
    "                         \n",
    "                     ],className=\"six columns\"),\n",
    "                     ##\n",
    "                     html.Div([\n",
    "                         dcc.RadioItems(id='selectAll',options=[\n",
    "                             {'label': 'select all features', 'value': 'all'},\n",
    "                             {'label': 'select manually', 'value': 'notAll'},]\n",
    "                                        ,value= None),\n",
    "                    html.H5(\"Select explicative features manually\"),        \n",
    "                    dcc.Dropdown(id='dropdownX',\n",
    "                        multi = True,\n",
    "                        placeholder='Select explicative var'),\n",
    "\n",
    "                     ],className=\"six columns\"),\n",
    "\n",
    "                     \n",
    "                 ],className=\"row\"),\n",
    "                html.Div([\n",
    "                     html.Br(),\n",
    "                     html.H6(\"Select percentage of splitting Data into: train and  test\"), \n",
    "                     html.Div(dcc.Slider(id='echSplit',  min=0.01, max=1,step=0.05, value=0.3,),\n",
    "                              style={'width': '20%','display': 'inline-block'},),\n",
    "                              html.Div(id='output-container-range-slider'),\n",
    "                     ]),\n",
    "            \n",
    "            ],style={\n",
    "                'borderRadius': '5px',\n",
    "                'backgroundColor' : '#e6ffe6',\n",
    "                'width': '80%',\n",
    "                'borderStyle': 'solid',\n",
    "                'borderRadius': '5px',\n",
    "                'borderColor': '#e1e1d0',\n",
    "                'position': 'static',\n",
    "                'marginLeft': 'auto',\n",
    "                'marginRight': 'auto',\n",
    "                'left': 0,\n",
    "                'right': 0\n",
    "            }\n",
    "        ) , \n",
    "\n",
    "#################################################################################################################        \n",
    "############### Features selection\n",
    "        \n",
    "        html.Div(children='Features selection', style={\n",
    "            'fontSize':'25px',\n",
    "            'textAlign': 'center',\n",
    "            'color': colors['text']\n",
    "        }),\n",
    "        \n",
    "        html.Div([\n",
    "            html.Div([\n",
    "                html.Div(children='Features selection criteria', style={\n",
    "                    'textAlign': 'center',\n",
    "                    'fontSize':'17px',\n",
    "                }),\n",
    "                dcc.RadioItems(id='selectVar',options=[\n",
    "                    {'label': 'RFE: Recursive Feature Elimination', 'value': 'RFE'},\n",
    "                    {'label': 'Delete Correlated Features', 'value': 'corr'},]\n",
    "                               ,value= None),\n",
    "                html.Br(),\n",
    "                html.Br(),\n",
    "                html.Div([html.Div('Pick a classifier for RFE')], style={'fontSize':'15px'}),\n",
    "                dcc.RadioItems(id='modelRFE',options=[\n",
    "                    {'label': 'Gradient Boosting', 'value': 'gbm'},\n",
    "                    {'label': 'Random Forest', 'value': 'random'},\n",
    "                    {'label': 'Decision Tree', 'value': 'DT'},\n",
    "                    {'label': 'Naive Bays', 'value': 'bays'},\n",
    "                    {'label': 'Regression Logistic', 'value': 'logreg'},\n",
    "                ],value= None),\n",
    "            \n",
    "                html.Br(),\n",
    "                html.Br(),\n",
    "                html.Div([\n",
    "                    html.Div([html.Div('Correlation threshold')], style={'fontSize':'15px'}),\n",
    "                    dcc.Slider(id='seuil',  min=0.01, max=1,step=0.05, value=0.7,),\n",
    "                    html.Div(id='seuilOut'),\n",
    "                ],style={'width': '30%'}),\n",
    "                    \n",
    "                \n",
    "                html.Button('Generate selection', id='buttonSelect' ),\n",
    "            ],className=\"six columns\"),\n",
    "            ###\n",
    "            html.Div([\n",
    "                html.Div(children='Results', style={\n",
    "                    'textAlign': 'center',\n",
    "                    'fontSize':'17px',\n",
    "                }),\n",
    "                #html.Div(id='resultSelection', children='Numbre of selected Features'),\n",
    "                html.Div(dt.DataTable(rows=[{}], id='tableBestFeat',row_selectable=True, filterable=True,\n",
    "                sortable=True,column_widths=[110, 110], row_height=28,)),\n",
    "               \n",
    "            ],className=\"six columns\"),\n",
    "            html.Div([\n",
    "\n",
    "                html.Div('Do you want to use the selected features ?'),                \n",
    "                dcc.RadioItems(id='useSelectedFeature',options=[\n",
    "                    {'label': 'Yes', 'value': 'yes'},\n",
    "                    {'label': 'No', 'value': 'no'},\n",
    "                ],value= None),                \n",
    "                \n",
    "            ],style={\n",
    "                'textAlign': 'center',\n",
    "                'fontSize':'18px',}\n",
    "            )\n",
    "\n",
    "        ],className=\"row\",\n",
    "            style={\n",
    "                'width': '80%',\n",
    "                'borderStyle': 'solid',\n",
    "                'borderRadius': '5px',\n",
    "                'borderColor': '#e1e1d0',\n",
    "                'backgroundColor' : '#e6f0ff',\n",
    "                'position': 'static',\n",
    "                'marginLeft': 'auto',\n",
    "                'marginRight': 'auto',\n",
    "                'left': 0,\n",
    "                'right': 0\n",
    "            }\n",
    "\n",
    "            \n",
    "        ), \n",
    "        \n",
    "        \n",
    "\n",
    "#################################################################################################################        \n",
    "##############    select classifier   #########\n",
    "\n",
    "        html.Div(children='Select a classifier', style={\n",
    "            'fontSize':'25px',\n",
    "            'textAlign': 'center',\n",
    "            'color': colors['text']\n",
    "        }),\n",
    "        ###############\n",
    "        html.Div([\n",
    "            html.Div([dcc.RadioItems(id='model',\n",
    "                                     options=[\n",
    "                                         {'label': 'mlp classifier', 'value':'mlp'},\n",
    "                                         {'label': 'mlp classifier with ACP ', 'value':'mlpACP'},\n",
    "                                         {'label': 'Gradient Boosting', 'value': 'gbm'},\n",
    "                                         {'label': 'AdaBoost', 'value':'adaBoost'},\n",
    "                                         {'label': 'Bagging Tree Classifier', 'value':'bagging'},\n",
    "                                         {'label': 'Random Forest', 'value': 'random'},\n",
    "                                         {'label': 'Decision Tree', 'value':'DT'},\n",
    "                                         {'label': 'Naive Bays', 'value': 'bays'},\n",
    "                                         {'label': 'logistic regression classifier', 'value': 'logreg'}\n",
    "                                     ],labelStyle={'display': 'inline-block'},value= None)],\n",
    "                     style={'width': '80%',\n",
    "                            'position': 'static',\n",
    "                            'marginLeft': 'auto',\n",
    "                            'marginRight': 'auto',}),\n",
    "            \n",
    "            html.Div(children='Select Parameter', \n",
    "                     style={'fontSize':'20px',\n",
    "                            'textAlign': 'center',\n",
    "                           }),\n",
    "            ####\n",
    "            html.Div([\n",
    "                html.Div([html.Div([html.Div('MLP')], style={'fontSize':'19px','color':'#00004d'}),\n",
    "                          html.Div('Default Paratmers:'),dcc.RadioItems(id='defaultMLP',\n",
    "                                                                options=[{'label': 'Yes', 'value':'T'}\n",
    "                                                                         ,{'label': 'No', 'value':'F'}\n",
    "                                                                        ],\n",
    "                                                                         value='T'  ),                        \n",
    "                          html.Div('Number of neurals:'),dcc.Input(id='neural', type='text') ,\n",
    "                          html.Div('Number of layers:'),dcc.Input(id='layers', type='text'),\n",
    "                          html.Div('Early stop:'),dcc.RadioItems(id='stop',\n",
    "                                                                options=[{'label': 'True', 'value':'T'}\n",
    "                                                                         ,{'label': 'False', 'value':'F'}\n",
    "                                                                        ],\n",
    "                                                                         value='T')\n",
    "                         ],className=\"six columns\"),\n",
    "                #\n",
    "                html.Div([html.Div([html.Div('Decision Tree,Random Froest, Gradient Boosting')],\n",
    "                                   style={'fontSize':'19px','color':'#00004d'}),\n",
    "                          html.Div('Default Paratmers:'),dcc.RadioItems(id='defaultDT',\n",
    "                                                                options=[{'label': 'Yes', 'value':'T'}\n",
    "                                                                         ,{'label': 'No', 'value':'F'}\n",
    "                                                                        ],                          \n",
    "                                                                         value='T'  ),                        \n",
    "                          html.Div('number of trees:'),dcc.Input(id='NEstimators', type='text'),\n",
    "                          html.Div('max depth:'),dcc.Input(id='maxDepth', type='text'),\n",
    "                          html.Div('Min sample split:'),dcc.Input(id='MinSampleSplit', type='text'),\n",
    "                          html.Div('Min sample leaf: '),dcc.Input(id='MinSampleLeaf', type='text'),\n",
    "                          html.Div('Max Feature: '),dcc.RadioItems(id='maxFeature',\n",
    "                                                                options=[{'label': 'auto :Max Feature =sqrt(n_features)', 'value':'auto'}\n",
    "                                                                         ,{'label': 'sqrt, Max Feature=sqrt(n_features)', 'value':'sqrt'}\n",
    "                                                                         ,{'label': 'log2, Max Feature =log2(n_features)', 'value':'sqrt'}\n",
    "                                                                         ,{'label': 'None, Max Feature =n_features', 'value':'None'}\n",
    "                                                                        ],\n",
    "                                                                         value='None')\n",
    "                         ],className=\"six columns\"),\n",
    "            ],className=\"row\"),\n",
    "        ],style={'borderRadius': '5px',\n",
    "                'backgroundColor' : '#e6ffe6',\n",
    "                # 'display': 'block',\n",
    "                'width': '80%',\n",
    "                'borderStyle': 'solid',\n",
    "                'borderRadius': '5px',\n",
    "                'borderColor': '#e1e1d0',\n",
    "                'position': 'static',\n",
    "                'marginLeft': 'auto',\n",
    "                'marginRight': 'auto',\n",
    "                'left': 0,\n",
    "                'right': 0\n",
    "                }\n",
    "        ),\n",
    "        html.Br(),\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "#########################################################################################################\"        \n",
    "####### model report \n",
    "        \n",
    "        html.Div(children='Model Report', style={\n",
    "            'fontSize':'25px',\n",
    "            'textAlign': 'center',\n",
    "            'color': colors['text']\n",
    "        }),\n",
    "        \n",
    "        html.Div([\n",
    "            html.Div([\n",
    "                html.Div(children='model report', style={\n",
    "                    'textAlign': 'center',\n",
    "                }),                \n",
    "                html.Button( 'Generate model report', id='report'),\n",
    "                html.Div(dt.DataTable(rows=[{}], id='modelReport',row_selectable=True, filterable=True,\n",
    "                sortable=True,column_widths=[130, 130], row_height=30,), style ={'align':\"center\"}),\n",
    "                html.Br(),\n",
    "                html.Button('Confusion Matrix',id='ButtonMatrix'),\n",
    "                html.Div(dt.DataTable(rows=[{}], id='matrix',row_selectable=True, filterable=True,\n",
    "                sortable=True,column_widths=[160, 160], row_height=50,)),\n",
    "                html.Div('Note: the column represent the predicted and the row represent the actual'),\n",
    "                \n",
    "            ],className=\"six columns\"),\n",
    "            html.Div([\n",
    "                html.Div(children='ROC Curve', style={\n",
    "                    'textAlign': 'center',\n",
    "                }),\n",
    "                html.Button('Genrate ROC cuve', id='roc' ),\n",
    "                dcc.Graph(id='my-graph'),                \n",
    "            ],className=\"six columns\"),\n",
    "\n",
    "        ],className=\"row\",\n",
    "            style={\n",
    "                'width': '80%',\n",
    "                'borderStyle': 'solid',\n",
    "                'borderRadius': '5px',\n",
    "                'borderColor': '#e1e1d0',\n",
    "                'backgroundColor' : '#e6f0ff',\n",
    "                'position': 'static',\n",
    "                'marginLeft': 'auto',\n",
    "                'marginRight': 'auto',\n",
    "                'left': 0,\n",
    "                'right': 0\n",
    "            }\n",
    "\n",
    "            \n",
    "        ), \n",
    "        \n",
    "#########################################################################################################\"        \n",
    "####### compare models\n",
    "        \n",
    "        html.Br(),\n",
    "        html.Div(children='Compare models', style={\n",
    "            'fontSize':'25px',\n",
    "            'textAlign': 'center',\n",
    "            'color': colors['text']\n",
    "        }), \n",
    "        html.Div([\n",
    "            #\n",
    "            html.Br(),        \n",
    "            dcc.Checklist(id='Multimodel',\n",
    "                          options=[\n",
    "                              {'label': 'mlp classifier', 'value':'mlp'},\n",
    "                              {'label': 'mlp classifier with ACP ', 'value':'mlpACP'},\n",
    "                              {'label': 'Gradient Boosting', 'value': 'gbm'},\n",
    "                              {'label': 'AdaBoost', 'value':'adaBoost'},\n",
    "                              {'label': 'Bagging Tree Classifier', 'value':'bagging'},\n",
    "                              {'label': 'Random Forest', 'value': 'random'},\n",
    "                              {'label': 'Decision Tree', 'value':'DT'},\n",
    "                              {'label': 'Naive Bays', 'value': 'bays'},\n",
    "                              {'label': 'logistic regression classifier', 'value': 'logreg'}\n",
    "                          ],\n",
    "                          values=['mlp','gbm'],\n",
    "                          labelStyle={'display': 'inline-block'},\n",
    "                          ),\n",
    "            \n",
    "            \n",
    "            html.Br(),        \n",
    "            html.Button('Genrate multi ROC cuve', id='Mroc'),\n",
    "            dcc.Graph(id='multiROC'),\n",
    "            html.Div(dt.DataTable(rows=[{}], id='compareTable',row_selectable=True, filterable=True,\n",
    "                sortable=True,column_widths=[160, 160], row_height=50,)),\n",
    "            \n",
    "        ],\n",
    "            style={\n",
    "                'width': '80%',\n",
    "                'borderStyle': 'solid',\n",
    "                'borderRadius': '5px',\n",
    "                'borderColor': '#e1e1d0',\n",
    "                'backgroundColor' : '#e6ffe6',\n",
    "                'position': 'static',\n",
    "                'marginLeft': 'auto',\n",
    "                'marginRight': 'auto',\n",
    "                'left': 0,\n",
    "                'right': 0\n",
    "            }            \n",
    "        ),\n",
    "\n",
    "#################################################################################################################        \n",
    "######## Make a prediction\n",
    "        \n",
    "        html.Br(),\n",
    "        html.Div(children='Make a prediction and download it ', style={\n",
    "            'fontSize':'25px',\n",
    "            'textAlign': 'center',\n",
    "        }), \n",
    "\n",
    "        html.Div([\n",
    "            html.H5(\"Upload Files\"),\n",
    "            dcc.Upload(\n",
    "                id='upload_pred',\n",
    "                children=html.Div([\n",
    "                    'Drag and Drop or ',\n",
    "                    html.A('Select Files')\n",
    "                ]),\n",
    "                style={\n",
    "                    'width': '100%',\n",
    "                    'height': '60px',\n",
    "                    'lineHeight': '60px',\n",
    "                    'borderWidth': '1px',\n",
    "                    'borderStyle': 'dashed',\n",
    "                    'borderRadius': '5px',\n",
    "                    'textAlign': 'center',\n",
    "                    'margin': '10px'\n",
    "                },\n",
    "                multiple=False),\n",
    "\n",
    "\n",
    "            html.Br(),\n",
    "            html.Div(dt.DataTable(rows=[{}], id='predict',row_selectable=True, filterable=True,\n",
    "            sortable=True,column_widths=[100, 100], row_height=30,)), \n",
    "            html.Br(),\n",
    "            html.Div(dcc.Input(id='url', type='text')),\n",
    "            html.Button('downlaod Prediction', id='download'),\n",
    "            html.Div(id='downloadResult',\n",
    "                 children='Enter the path and click to download the prediction table'),\n",
    "            \n",
    "        ],\n",
    "            style={\n",
    "                'width': '80%',\n",
    "                'borderStyle': 'solid',\n",
    "                'borderRadius': '5px',\n",
    "                'borderColor': '#e1e1d0',\n",
    "                'backgroundColor' : '#e6f0ff',\n",
    "                'position': 'static',\n",
    "                'marginLeft': 'auto',\n",
    "                'marginRight': 'auto',\n",
    "                'left': 0,\n",
    "                'right': 0\n",
    "            } \n",
    "        )\n",
    "\n",
    "        \n",
    "    ]\n",
    ")\n",
    "#################################################################################################################        \n",
    "#################################################################################################################        \n",
    "#################################################################################################################        \n",
    "#################################################################################################################        \n",
    "#################################################################################################################        \n",
    "### upload data\n",
    "\n",
    "def parse_contents(contents, filename):\n",
    "    content_type, content_string = contents.split(',')\n",
    "\n",
    "    decoded = base64.b64decode(content_string)\n",
    "    try:\n",
    "        if 'csv' in filename:\n",
    "            # Assume that the user uploaded a CSV file\n",
    "            df = pd.read_csv(\n",
    "                io.StringIO(decoded.decode('utf-8')), sep=';')\n",
    "            print('csv uploaded')\n",
    "        elif 'xls' in filename:\n",
    "            # Assume that the user uploaded an excel file\n",
    "            df = pd.read_excel(io.BytesIO(decoded))\n",
    "            print('xls uploaded')\n",
    "\n",
    "\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return None\n",
    "\n",
    "    return df\n",
    "#################\n",
    "\n",
    "@app.callback(Output('table', 'rows'),\n",
    "              [Input('upload-data', 'contents'),\n",
    "               Input('upload-data', 'filename')])\n",
    "def update_output(contents, filename):\n",
    "    if contents is not None:\n",
    "        df = parse_contents(contents, filename)\n",
    "        if df is not None:\n",
    "            print('data ulloded  successflly')\n",
    "            return df.to_dict('records')\n",
    "        else:\n",
    "            print(' no upload data none')\n",
    "            return [{}]\n",
    "    else:\n",
    "        print('contenant is none !')\n",
    "        return [{}]\n",
    "##################\n",
    "\n",
    "@app.callback(Output('summary', 'rows'),\n",
    "              [Input('upload-data', 'contents'),\n",
    "               Input('upload-data', 'filename')])\n",
    "def summary (contents, filename):\n",
    "    if contents is not None:\n",
    "        df = parse_contents(contents, filename)\n",
    "        desc=df.describe()\n",
    "        desc['description'] =desc.index \n",
    "        cols = desc.columns.tolist()\n",
    "        desc = desc[[cols[-1]] + cols[:-1]] \n",
    "        return desc.to_dict('records')\n",
    "    else:\n",
    "        return [{}]\n",
    "\n",
    "    \n",
    "############################################################################################################\n",
    "################## select columns\n",
    "\n",
    "@app.callback(Output('dropdownX', 'options'),\n",
    "              [Input('table', 'rows')])\n",
    "def update_filter_column_options(tablerows):\n",
    "    dff = pd.DataFrame(tablerows) # <- problem! dff stays empty even though table was uploaded\n",
    "\n",
    "    print (\"updating... dff empty?:\", dff.empty )#result is True, labels stay empty\n",
    "\n",
    "    return [{'label': i, 'value': i} for i in sorted(list(dff))]\n",
    "\n",
    "@app.callback(Output('dropdownY', 'options'),\n",
    "              [Input('table', 'rows')])\n",
    "def update_filter_column_options(tablerow):\n",
    "    dfy = pd.DataFrame(tablerow) # <- problem! dff stays empty even though table was uploaded\n",
    "\n",
    "    print (\"updating... dff empty?:\", dfy.empty )#result is True, labels stay empty\n",
    "\n",
    "    return [{'label': i, 'value': i} for i in sorted(list(dfy))]\n",
    "\n",
    "@app.callback(Output('subs', 'options'),\n",
    "              [Input('table', 'rows')])\n",
    "def update_filter_column_options(tablerow):\n",
    "    df = pd.DataFrame(tablerow) # <- problem! dff stays empty even though table was uploaded\n",
    "\n",
    "    print (\"updating... dff empty?:\", df.empty )#result is True, labels stay empty\n",
    "\n",
    "    return [{'label': i, 'value': i} for i in sorted(list(df))]\n",
    "\n",
    "#####################\n",
    "@app.callback(Output('output-container-range-slider', 'children'),\n",
    "              [Input('echSplit', 'value')])\n",
    "def select_output_message(value):\n",
    "    return  'You have selected \"{}\" %'.format(value*100)\n",
    "\n",
    "    \n",
    "############################################################################################################\n",
    "##################### Feature selection\n",
    "\n",
    "@app.callback(Output('seuilOut','children'),\n",
    "              [Input('seuil','value')])\n",
    "def seuil_output(value):\n",
    "    return 'You have selected \"{}\" %'.format(value)\n",
    "\n",
    "@app.callback(Output('tableBestFeat', 'rows'),\n",
    "              [Input('table', 'rows'),\n",
    "               Input('selectVar', 'value'),\n",
    "               Input('modelRFE', 'value'),\n",
    "               Input('seuil', 'value'),\n",
    "               Input('buttonSelect','n_clicks'),\n",
    "               Input('dropdownX', 'value'),\n",
    "               Input('dropdownY', 'value'),\n",
    "               Input('echSplit', 'value'),\n",
    "               Input ('selectAll', 'value'),\n",
    "               Input ('subs', 'value'),\n",
    "              ])\n",
    "def FeaturesSelection (table,selectVar,modelRFE,seuil,buttonSelect,xvar, yvar, ech,selectAll,subs):\n",
    "    if (buttonSelect==None): \n",
    "        return [{}]\n",
    "    else:\n",
    "        df =  pd.DataFrame(table)\n",
    "        if (selectAll== 'all') :\n",
    "            x=df.drop([yvar,subs], axis=1)\n",
    "            print('selected all var for featres selection ')\n",
    "        else : \n",
    "            x=df[xvar]\n",
    "            print('not  all var for featres selection')\n",
    "\n",
    "\n",
    "        y=df[yvar]\n",
    "        y=np.ravel(y)\n",
    "        if (selectVar=='RFE'): \n",
    "            if(modelRFE=='gbm'): model=GradientBoostingClassifier(n_estimators=10)\n",
    "            if(modelRFE=='random'):model=RandomForestClassifier(n_estimators=10)\n",
    "\n",
    "            if(modelRFE=='logreg'):model=BernoulliNB()\n",
    "            if(modelRFE=='bays'):model=LogisticRegression()\n",
    "            if(modelRFE=='DT'):model=tree.DecisionTreeClassifier()\n",
    "            \n",
    "            rfe=RFE(model)\n",
    "            fit = rfe.fit(x,y)\n",
    "            data={'Features':x.columns, 'Selected': fit.support_, 'Rank' : fit.ranking_}\n",
    "            selectedTable=pd.DataFrame(data)\n",
    "            booleandf = selectedTable.select_dtypes(include=[bool])\n",
    "            booleanDictionary = {True: 'TRUE', False: 'FALSE'}\n",
    "            for column in booleandf:\n",
    "                selectedTable[column] = selectedTable[column].map(booleanDictionary)            \n",
    "\n",
    "        else: \n",
    "            selectedTable=correlation(x,seuil)\n",
    "            selectedTable['*'] =selectedTable.index \n",
    "            cols = selectedTable.columns.tolist()\n",
    "            selectedTable = selectedTable[[cols[-1]] + cols[:-1]]         \n",
    "        return selectedTable.to_dict('records')\n",
    "def correlation(dataset, threshold):\n",
    "    col_corr = set() # Set of all the names of deleted columns\n",
    "    corr_matrix = dataset.corr()\n",
    "    for i in range(len(corr_matrix.columns)):\n",
    "        for j in range(i):\n",
    "            if corr_matrix.iloc[i, j] >= threshold:\n",
    "                colname = corr_matrix.columns[i] # getting the name of column\n",
    "                col_corr.add(colname)\n",
    "                if colname in dataset.columns:\n",
    "                    del dataset[colname] # deleting the column from the dataset\n",
    "                corrMatrix=dataset.corr()\n",
    "\n",
    "    return (corrMatrix)\n",
    "\n",
    "##############################################################################################################\n",
    "############################ model report\n",
    "\n",
    "@app.callback(Output('modelReport', 'rows'),\n",
    "              [Input('table', 'rows'),\n",
    "               Input('dropdownX', 'value'),\n",
    "               Input('dropdownY', 'value'),\n",
    "               Input('echSplit', 'value'),\n",
    "               Input ('selectAll', 'value'),\n",
    "               Input ('subs', 'value'),\n",
    "               Input('model', 'value'),\n",
    "               Input('report', 'n_clicks'),\n",
    "               # MLP parameters\n",
    "               Input('defaultMLP','value'),\n",
    "               Input('neural','value'),\n",
    "               Input('layers','value'),\n",
    "               Input('stop','value'),\n",
    "               # DT paramettres \n",
    "               Input('defaultDT','value'),\n",
    "               Input('NEstimators','value'),\n",
    "               Input('maxDepth','value'),\n",
    "               Input('MinSampleSplit','value'),\n",
    "               Input('MinSampleLeaf','value'),\n",
    "               Input('maxFeature','value'),\n",
    "               #selecte features\n",
    "               Input('tableBestFeat', 'rows'),\n",
    "               Input('selectVar', 'value'),\n",
    "               Input('useSelectedFeature','value')\n",
    "            ])\n",
    "\n",
    "def modelReport (tablerows, xvar,yvar,ech,selectAll, subs, mod, button,\n",
    "                 defaultMLP,neural,layers,stop,\n",
    "                 defaultDT,NEstimators,maxDepth,MinSampleSplit,MinSampleLeaf,maxFeature,\n",
    "                 tableBestFeat, selectVar, useSelectedFeature):\n",
    "    \n",
    "    if (button ==None):\n",
    "        return [{}]\n",
    "    else:\n",
    "        moel=None \n",
    "        df =  pd.DataFrame(tablerows)\n",
    "        y=df[yvar]\n",
    "        y=np.ravel(y)\n",
    "        if (useSelectedFeature== 'yes'):\n",
    "            print('you choosed to work with selected features')    \n",
    "            tableBestFeat=pd.DataFrame(tableBestFeat)\n",
    "            if (selectVar=='RFE'):\n",
    "                Features=tableBestFeat.loc[tableBestFeat['Selected'] == 'TRUE']['Features']\n",
    "                x=df[Features]\n",
    "                print('REF var loaded successfully')\n",
    "            else:\n",
    "                Features=tableBestFeat['*'].tolist()\n",
    "                x=df[Features]\n",
    "                print('corr deleted var loaded successfully')\n",
    "        else: \n",
    "            print('you dicided to work with the inatial var')\n",
    "            if (selectAll== 'all') :\n",
    "                x=df.drop([yvar,subs], axis=1)\n",
    "                print('selected all var loaded ')\n",
    "            else : \n",
    "                x=df[xvar]\n",
    "                print('not  all var  loaded')\n",
    "        x_train, x_test, y_train, y_test = train_test_split(x, y, test_size =float(ech) ,  stratify=y)\n",
    "        earlyStop=True\n",
    "### log reg\n",
    "        if (mod == 'logreg'):\n",
    "            import time\n",
    "            Title='Logistic regression'\n",
    "            start_time = time.time() \n",
    "            logreg = LogisticRegression()\n",
    "            model=logreg.fit(x_train,y_train)\n",
    "            temps=time.time() - start_time\n",
    "            # save for confusion matrix\n",
    "            predict_y =   model.predict(x_test)\n",
    "            confusion_matrix = metrics.confusion_matrix(y_test, predict_y)\n",
    "            confusion_matrix=pd.DataFrame(confusion_matrix)\n",
    "            confusion_matrix.to_csv(lien+\"CMlogreg.csv\")\n",
    "            ## save for plot\n",
    "            fp, tp, threshold= metrics.roc_curve(y_test, model.predict_proba(x_test)[:,1])\n",
    "            AUC= metrics.auc(fp, tp)\n",
    "            data={ 'fp':  fp ,'tp': tp}\n",
    "            df = pd.DataFrame(data)\n",
    "            df.to_csv(lien+\"plotLogreg.csv\")\n",
    "\n",
    "            print('logistic regression done')\n",
    "### mlp            \n",
    "        elif (mod =='mlp' ):\n",
    "            import time\n",
    "            start_time = time.time() \n",
    "            Title='Multi Layer Perceptron'\n",
    "            if (defaultMLP=='T'):\n",
    "                mlp=MLPClassifier()\n",
    "            else:\n",
    "                if(stop=='F'): earlStop=False\n",
    "                if (float(layers)==1):\n",
    "                    mlp=MLPClassifier(activation='relu', alpha=0.001, batch_size='auto', beta_1=0.9,\n",
    "                           beta_2=0.899, early_stopping=earlyStop , epsilon=1e-07,\n",
    "                           hidden_layer_sizes=(int(neural)), learning_rate='invscaling',\n",
    "                           learning_rate_init=0.1, max_iter=500, momentum=0.9,\n",
    "                           nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
    "                           shuffle=True, solver='adam', tol=0.01, validation_fraction=0.1,\n",
    "                           verbose=False, warm_start=False)\n",
    "                elif (float(layers)==2):\n",
    "                    mlp=MLPClassifier(activation='relu', alpha=0.001, batch_size='auto', beta_1=0.9,\n",
    "                           beta_2=0.899, early_stopping=earlyStop , epsilon=1e-07,\n",
    "                           hidden_layer_sizes=(int(neural),int(neural)), learning_rate='invscaling',\n",
    "                           learning_rate_init=0.1, max_iter=500, momentum=0.9,\n",
    "                           nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
    "                           shuffle=True, solver='adam', tol=0.01, validation_fraction=0.1,\n",
    "                           verbose=False, warm_start=False)                \n",
    "                elif (float(layers)==3):\n",
    "                    mlp=MLPClassifier(activation='relu', alpha=0.001, batch_size='auto', beta_1=0.9,\n",
    "                           beta_2=0.899, early_stopping=earlyStop , epsilon=1e-07,\n",
    "                           hidden_layer_sizes=(int(neural),int(neural), int(neural)), learning_rate='invscaling',\n",
    "                           learning_rate_init=0.1, max_iter=500, momentum=0.9,\n",
    "                           nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
    "                           shuffle=True, solver='adam', tol=0.01, validation_fraction=0.1,\n",
    "                           verbose=False, warm_start=False)\n",
    "                \n",
    "\n",
    "            model=mlp.fit(x_train, y_train)\n",
    "            temps=time.time() - start_time\n",
    "            # save for confusion matrix\n",
    "            predict_y =   model.predict(x_test)\n",
    "            confusion_matrix = metrics.confusion_matrix(y_test, predict_y)\n",
    "            confusion_matrix=pd.DataFrame(confusion_matrix)\n",
    "            confusion_matrix.to_csv(lien+\"CMmlp.csv\")            \n",
    "            ## save for plot\n",
    "            fp, tp, threshold= metrics.roc_curve(y_test, model.predict_proba(x_test)[:,1])\n",
    "            AUC= metrics.auc(fp, tp)\n",
    "            data={ 'fp':  fp ,'tp': tp}\n",
    "            df = pd.DataFrame(data)\n",
    "            df.to_csv(lien+\"plotMlp.csv\")\n",
    "\n",
    "            print('mlp done for model report')\n",
    "### mlpACP            \n",
    "        elif (mod=='mlpACP'):\n",
    "            import time\n",
    "            start_time = time.time()\n",
    "            Title='MLP based on ACP'\n",
    "            pca= PCA(n_components=37, whiten= True )\n",
    "            pca.fit(x)\n",
    "            X_pca = pca.transform(x)\n",
    "            x_train, x_test, y_train, y_test = train_test_split(X_pca, y, test_size =0.3 )\n",
    "            mlpACP = MLPClassifier(hidden_layer_sizes=(30),max_iter=500)\n",
    "            model=mlpACP.fit(x_train,y_train)\n",
    "            temps= time.time() - start_time\n",
    "            ##save for confusion matrix \n",
    "            predict_y =   model.predict(x_test)\n",
    "            confusion_matrix = metrics.confusion_matrix(y_test, predict_y)\n",
    "            ## save for plot\n",
    "            fp, tp, threshold= metrics.roc_curve(y_test, model.predict_proba(x_test)[:,1])\n",
    "            AUC= metrics.auc(fp, tp)\n",
    "            data={ 'fp':  fp ,'tp': tp}\n",
    "            df = pd.DataFrame(data)\n",
    "            confusion_matrix=pd.DataFrame(confusion_matrix)\n",
    "            df.to_csv(lien+\"plotMlpACP.csv\")\n",
    "\n",
    "            confusion_matrix.to_csv(lien+\"CMmlpACP.csv\")\n",
    "            print('mlpACP joblibd for model report')\n",
    "### gbm            \n",
    "        elif (mod =='gbm' ):\n",
    "            Title='Gradient Boosting'\n",
    "            import time\n",
    "            start_time = time.time()\n",
    "            if (defaultDT=='T'):\n",
    "                gbm = GradientBoostingClassifier()\n",
    "            else:\n",
    "                if (maxFeature=='None'):\n",
    "                    gbm = GradientBoostingClassifier(n_estimators=int(NEstimators), max_depth=int(maxDepth),\n",
    "                                                     min_samples_split=int(MinSampleSplit),\n",
    "                                                     min_samples_leaf=int(MinSampleLeaf))\n",
    "                else:\n",
    "                    gbm = GradientBoostingClassifier(n_estimators=int(NEstimators), max_depth=int(maxDepth),\n",
    "                                                     min_samples_split=int(MinSampleSplit),\n",
    "                                                     min_samples_leaf=int(MinSampleLeaf),\n",
    "                                                     max_features=maxFeature)                \n",
    "            model=gbm.fit(x_train, y_train)\n",
    "            temps= time.time() - start_time\n",
    "            # save for confusion matrix\n",
    "            predict_y =   model.predict(x_test)\n",
    "            confusion_matrix = metrics.confusion_matrix(y_test, predict_y)\n",
    "            confusion_matrix=pd.DataFrame(confusion_matrix)\n",
    "            confusion_matrix.to_csv(lien+\"CMgbm.csv\")\n",
    "            ## save for plot\n",
    "            fp, tp, threshold= metrics.roc_curve(y_test, model.predict_proba(x_test)[:,1])\n",
    "            AUC= metrics.auc(fp, tp)\n",
    "            data={ 'fp':  fp ,'tp': tp}\n",
    "            df = pd.DataFrame(data)\n",
    "            confusion_matrix=pd.DataFrame(confusion_matrix)\n",
    "            df.to_csv(lien+\"plotGbm.csv\")\n",
    "\n",
    "            print('classification with GBM done successfully')\n",
    "###random\n",
    "        elif (mod =='random' ):\n",
    "            Title= 'Rondom forest'\n",
    "            import time\n",
    "            start_time = time.time()\n",
    "            if (defaultDT=='T'):\n",
    "                random= RandomForestClassifier()\n",
    "            else:\n",
    "                if (maxFeature=='None'):\n",
    "                    random= RandomForestClassifier(n_estimators=int(NEstimators), max_depth=int(maxDepth),\n",
    "                                                     min_samples_split=int(MinSampleSplit),\n",
    "                                                     min_samples_leaf=int(MinSampleLeaf))\n",
    "                else:\n",
    "                    random= RandomForestClassifier(n_estimators=int(NEstimators), max_depth=int(maxDepth),\n",
    "                                                     min_samples_split=int(MinSampleSplit),\n",
    "                                                     min_samples_leaf=int(MinSampleLeaf),\n",
    "                                                     max_features=maxFeature)  \n",
    "          \n",
    "            model= random.fit(x_train, y_train)\n",
    "            temps= time.time() - start_time\n",
    "            # save for confusion matrix\n",
    "            predict_y =   model.predict(x_test)\n",
    "            confusion_matrix = metrics.confusion_matrix(y_test, predict_y)\n",
    "            confusion_matrix=pd.DataFrame(confusion_matrix)\n",
    "            confusion_matrix.to_csv(lien+\"CMrandom.csv\")\n",
    "            ## save for plot\n",
    "            fp, tp, threshold= metrics.roc_curve(y_test, model.predict_proba(x_test)[:,1])\n",
    "            AUC= metrics.auc(fp, tp)\n",
    "            data={ 'fp':  fp ,'tp': tp}\n",
    "            df = pd.DataFrame(data)\n",
    "            df.to_csv(lien+\"plotRandom.csv\")\n",
    "\n",
    "            print('classification with Random Forest done successfully')\n",
    "### ababoost                \n",
    "        elif(mod=='adaBoost'):\n",
    "            Title='AdaBoost'\n",
    "            import time\n",
    "            start_time = time.time()\n",
    "            if (defaultDT=='T'):\n",
    "                ada = AdaBoostClassifier( )\n",
    "            else:\n",
    "                ada = AdaBoostClassifier(n_estimators=int(NEstimators) )\n",
    "            model=ada.fit(x_train, y_train)\n",
    "            temps= time.time() - start_time\n",
    "            #save for  confusion matrix\n",
    "            predict_y =   model.predict(x_test)\n",
    "            confusion_matrix = metrics.confusion_matrix(y_test, predict_y)\n",
    "            confusion_matrix=pd.DataFrame(confusion_matrix)\n",
    "            confusion_matrix.to_csv(lien+\"CMadaBoost.csv\")\n",
    "            ## save for plot\n",
    "            fp, tp, threshold= metrics.roc_curve(y_test, model.predict_proba(x_test)[:,1])\n",
    "            AUC= metrics.auc(fp, tp)\n",
    "            data={ 'fp':  fp ,'tp': tp}\n",
    "            df = pd.DataFrame(data)\n",
    "            df.to_csv(lien+\"plotAdaBoost.csv\")\n",
    "\n",
    "            print('classification with adaBoost joblibd successfully')\n",
    "### bagging\n",
    "        elif(mod=='bagging'):\n",
    "            Title='Bagging'\n",
    "            import time\n",
    "            start_time = time.time()\n",
    "            if (defaultDT=='T'):\n",
    "                ada = BaggingClassifier( )\n",
    "            else:\n",
    "                ada = BaggingClassifier(n_estimators=int(NEstimators) )\n",
    "            temps= time.time() - start_time\n",
    "            model=ada.fit(x_train, y_train)\n",
    "            ## save  for confuision matrix\n",
    "            predict_y =   model.predict(x_test)\n",
    "            confusion_matrix = metrics.confusion_matrix(y_test, predict_y)\n",
    "            confusion_matrix=pd.DataFrame(confusion_matrix)\n",
    "            confusion_matrix.to_csv(lien+\"CMbagging.csv\")\n",
    "            ## save for plot\n",
    "            fp, tp, threshold= metrics.roc_curve(y_test, model.predict_proba(x_test)[:,1])\n",
    "            AUC= metrics.auc(fp, tp)\n",
    "            data={ 'fp':  fp ,'tp': tp}\n",
    "            df = pd.DataFrame(data)\n",
    "            df.to_csv(lien+\"plotBagging.csv\")\n",
    "\n",
    "            print('classification with Bagging joblibd successfully')\n",
    "### DT ###            \n",
    "        elif (mod=='DT'):\n",
    "            import time\n",
    "            start_time = time.time()\n",
    "            Title='Decision Tree'\n",
    "            if (defaultDT=='T'):\n",
    "                DT=tree.DecisionTreeClassifier(min_samples_leaf=0.35,min_samples_split=0.01,max_depth=7)\n",
    "            else:\n",
    "                if (maxFeature=='None'):\n",
    "                    DT=tree.DecisionTreeClassifier( max_depth=int(maxDepth),\n",
    "                                                     min_samples_split=int(MinSampleSplit),\n",
    "                                                     min_samples_leaf=int(MinSampleLeaf))\n",
    "                else:\n",
    "                    DT=tree.DecisionTreeClassifier( max_depth=int(maxDepth),\n",
    "                                                     min_samples_split=int(MinSampleSplit),\n",
    "                                                     min_samples_leaf=int(MinSampleLeaf),\n",
    "                                                     max_features=maxFeature)\n",
    " \n",
    "            model=DT.fit(x_train, y_train)\n",
    "            temps= time.time() - start_time\n",
    "            ## save for confusion Matrix\n",
    "            predict_y =   model.predict(x_test)\n",
    "            confusion_matrix = metrics.confusion_matrix(y_test, predict_y)\n",
    "            confusion_matrix=pd.DataFrame(confusion_matrix)\n",
    "            confusion_matrix.to_csv(lien+\"CMDT.csv\")\n",
    "            ## save for plot\n",
    "            fp, tp, threshold= metrics.roc_curve(y_test, model.predict_proba(x_test)[:,1])\n",
    "            AUC= metrics.auc(fp, tp)\n",
    "            data={ 'fp':  fp ,'tp': tp}\n",
    "            df = pd.DataFrame(data)\n",
    "            df.to_csv(lien+\"plotDT.csv\")\n",
    "\n",
    "            print('DT  done with specific parameter')\n",
    "### bayes ####           \n",
    "        elif(mod== 'bays'):\n",
    "            import time\n",
    "            start_time = time.time()\n",
    "            Title='Naive Bays'\n",
    "            bays = BernoulliNB()\n",
    "            model= bays.fit(x_train, y_train)\n",
    "            temps= time.time() - start_time\n",
    "            print('Naive Byas  done')\n",
    "            ## save for confusion matrix\n",
    "            predict_y =   model.predict(x_test)\n",
    "            confusion_matrix = metrics.confusion_matrix(y_test, predict_y)\n",
    "            confusion_matrix=pd.DataFrame(confusion_matrix)\n",
    "            confusion_matrix.to_csv(lien+\"CMbays.csv\")\n",
    "            ## save for plot\n",
    "            fp, tp, threshold= metrics.roc_curve(y_test, model.predict_proba(x_test)[:,1])\n",
    "            AUC= metrics.auc(fp, tp)\n",
    "            data={ 'fp':  fp ,'tp': tp}\n",
    "            df = pd.DataFrame(data)\n",
    "            df.to_csv(lien+\"plotBays.csv\")\n",
    "\n",
    "            print('classification with Niave Bays joblibd successfully')\n",
    "### evaluation             \n",
    "        AUC = metrics.auc(fp, tp)\n",
    "        model_score =    model.score(x_test,y_test)\n",
    "\n",
    "        #K-folds cross validaion\n",
    "        cv_score = cross_validation.cross_val_score(  model, x_test,y_test, cv=3, scoring='roc_auc')   \n",
    "        cv_mean=np.mean(cv_score)\n",
    "        confusion_matrix = metrics.confusion_matrix(y_test, predict_y)\n",
    "        TN= confusion_matrix[0, 0]                \n",
    "        FP=confusion_matrix[0, 1]\n",
    "        FN=confusion_matrix[1, 0]\n",
    "        TP=confusion_matrix[1, 1] \n",
    "        #false negative rate error type I \n",
    "        fnr=FN/(FN+ TP)\n",
    "        #False negaive rate error type II\n",
    "        fpr=FP/(FP+TN)\n",
    "        RSS = ((predict_y- y_test) ** 2).sum()\n",
    "        k=x.shape[1]\n",
    "        AIC= 2*k - 2*math.log(RSS )\n",
    "        report=pd.DataFrame({'creteria':['Model','Time(seconds)','Accuracy','erreur I','erreurII' ,'AUC','CV ACU','AIC','som error']})\n",
    "\n",
    "        report['Value']=[Title,temps,model_score,fnr,fpr,AUC, cv_mean,AIC,RSS]\n",
    "        print('Report done successflly')\n",
    "       \n",
    "        ###\n",
    "        return  report.to_dict('records')\n",
    "    \n",
    "\n",
    "#####################\n",
    "@app.callback(Output('matrix', 'rows'),[Input('table', 'rows'),\n",
    "               Input('dropdownX', 'value'),\n",
    "               Input('dropdownY', 'value'),\n",
    "               Input ('selectAll', 'value'),\n",
    "               Input ('subs', 'value'),\n",
    "               Input ('model', 'value'),\n",
    "               Input ('echSplit', 'value'),\n",
    "               Input ('ButtonMatrix', 'n_clicks'),\n",
    "                #selecte features\n",
    "               Input('tableBestFeat', 'rows'),\n",
    "               Input('selectVar', 'value'),\n",
    "               Input('useSelectedFeature','value')\n",
    "            ])\n",
    "def matrixDef (tablerows, xvar,yvar, selectAll, subs, mod,ech, button,\n",
    "               tableBestFeat, selectVar, useSelectedFeature):\n",
    "    if (button ==None):\n",
    "        return [{}]\n",
    "    else:\n",
    "        model=None\n",
    "        df =  pd.DataFrame(tablerows)\n",
    "        y=df[yvar]\n",
    "        y=np.ravel(y)\n",
    "        if (useSelectedFeature== 'yes'):\n",
    "            print('you choosed to work with selected features')    \n",
    "            tableBestFeat=pd.DataFrame(tableBestFeat)\n",
    "            if (selectVar=='RFE'):\n",
    "                Features=tableBestFeat.loc[tableBestFeat['Selected'] == 'TRUE']['Features']\n",
    "                x=df[Features]\n",
    "                print('REF var loaded successfully')\n",
    "            else:\n",
    "                Features=tableBestFeat['*'].tolist()\n",
    "                x=df[Features]\n",
    "                print('corr deleted var loaded successfully')\n",
    "        else: \n",
    "            print('you dicided to work with the inatial var')\n",
    "            if (selectAll== 'all') :\n",
    "                x=df.drop([yvar,subs], axis=1)\n",
    "                print('selected all var loaded  to compute Confucion Matirx')\n",
    "            else : \n",
    "                x=df[xvar]\n",
    "                print('not all var loaded  to compute Confucion Matirx')\n",
    "\n",
    "        if(mod == 'logreg'):\n",
    "            titre=' logistic Regression'\n",
    "            m= pd.read_csv(lien+\"CMlogreg.csv\",sep=',')\n",
    "            print('confusion martix logreg done')\n",
    "            \n",
    "        elif (mod=='mlp' ):\n",
    "            titre='MLPerceptron'\n",
    "            m= pd.read_csv(lien+\"CMmlp.csv\",sep=',')\n",
    "            print('confusion martix mlp done')\n",
    "            \n",
    "        elif (mod=='gbm'):\n",
    "            titre='Gradient Boosting'\n",
    "            m= pd.read_csv(lien+\"CMgbm.csv\",sep=',')\n",
    "            print('confusion martix gbm done')\n",
    "        elif (mod=='random'):   \n",
    "            titre='Random Forest'\n",
    "            m= pd.read_csv(lien+\"CMrandom.csv\",sep=',')\n",
    "            print('confusion martix random forest done')\n",
    "            \n",
    "        elif (mod=='adaBoost'):    \n",
    "            titre='AdaBoost Tree'\n",
    "            m= pd.read_csv(lien+\"CMada.csv\",sep=',')\n",
    "\n",
    "            print('confusion martix adaBoost  done')        \n",
    "        elif (mod=='bagging'):    \n",
    "            titre='bagging'\n",
    "            m= pd.read_csv(lien+\"CMbagging.csv\",sep=',')\n",
    "            print('confusion martix baggib Tree done')\n",
    "        elif (mod=='DT'):    \n",
    "            titre= 'Decision Tree'\n",
    "            m= pd.read_csv(lien+\"CMDT.csv\",sep=',')\n",
    "            print('confusion martix DT done')\n",
    "        elif('mlpACP'== mod):\n",
    "            titre='MLPerceptron ACP'\n",
    "            m= pd.read_csv(lien+\"CMmlpACP.csv\",sep=',')\n",
    "            print('confucion matrix mlpACP done')\n",
    "            \n",
    "        elif('bays'== mod):\n",
    "            titre='Bayes'\n",
    "            m= pd.read_csv(lien+\"CMbays.csv\",sep=',')\n",
    "            print('confusion martix bays done')\n",
    "        data={titre:['actuel 0','actuel 1'],'predicted 0':[m.iloc[0]['0'],m.iloc[1]['0'] ], 'predicted 1':[m.iloc[0]['1'],m.iloc[1]['1'] ] }\n",
    "        data=pd.DataFrame(data)\n",
    "        print(data)\n",
    "        return data.to_dict('records')\n",
    "    \n",
    "#########################################################################################################\n",
    "#####################  roc plot\n",
    "\n",
    "\n",
    "\n",
    "#####################\n",
    "@app.callback(Output('my-graph', 'figure'),\n",
    "              [Input('table', 'rows'),\n",
    "               Input('dropdownX', 'value'),\n",
    "               Input('dropdownY', 'value'),\n",
    "               Input ('selectAll', 'value'),\n",
    "               Input ('subs', 'value'),\n",
    "               Input ('model', 'value'),\n",
    "               Input ('echSplit', 'value'),\n",
    "               Input ('roc','n_clicks'),\n",
    "                #selecte features\n",
    "               Input('tableBestFeat', 'rows'),\n",
    "               Input('selectVar', 'value'),\n",
    "               Input('useSelectedFeature','value')\n",
    "              ])\n",
    "\n",
    "def RocPlot (tablerows, xvar,yvar, selectAll, subs, mod , ech, button,\n",
    "               tableBestFeat, selectVar, useSelectedFeature):\n",
    "    if (button ==None):\n",
    "        return [{}]\n",
    "    else:\n",
    "        model=None\n",
    "        df =  pd.DataFrame(tablerows)\n",
    "        y=df[yvar]\n",
    "        y=np.ravel(y)\n",
    "        if (useSelectedFeature== 'yes'):\n",
    "            print('you choosed to work with selected features')    \n",
    "            tableBestFeat=pd.DataFrame(tableBestFeat)\n",
    "            if (selectVar=='RFE'):\n",
    "                Features=tableBestFeat.loc[tableBestFeat['Selected'] == 'TRUE']['Features']\n",
    "                x=df[Features]\n",
    "                print('REF var loaded successfully')\n",
    "            else:\n",
    "                Features=tableBestFeat['*'].tolist()\n",
    "                x=df[Features]\n",
    "                print('corr deleted var loaded successfully')\n",
    "        else: \n",
    "            print('you dicided to work with the inatial var')\n",
    "            if (selectAll== 'all') :\n",
    "                x=df.drop([yvar,subs], axis=1)\n",
    "                print('selected all var loaded  to compute Confucion Matirx')\n",
    "            else : \n",
    "                x=df[xvar]\n",
    "                print('not all var loaded  to compute Confucion Matirx')\n",
    "        x_train, x_test, y_train, y_test = train_test_split(x, y, test_size =float(ech) ,  stratify=y)\n",
    "\n",
    "        if('logreg'== mod):\n",
    "            Title='Logistic Regression'\n",
    "            m= pd.read_csv(lien+\"plotLogreg.csv\",sep=',')\n",
    "            print('Logistic reg model loaded for plot')\n",
    "\n",
    "        elif('mlp'== mod):\n",
    "            Title='Multi Layer perceptron'\n",
    "            m= pd.read_csv(lien+\"plotMlp.csv\",sep=',')\n",
    "            print('mlp model loaded for plot')\n",
    "\n",
    "        elif('gbm'== mod):\n",
    "            Title='Gradient Boosting'\n",
    "            m= pd.read_csv(lien+\"plotGbm.csv\",sep=',')\n",
    "            print('gbm model loaded for plot')\n",
    "\n",
    "        elif('random'== mod):\n",
    "            Title='Random Forest'\n",
    "            m= pd.read_csv(lien+\"plotRandom.csv\",sep=',')\n",
    "            print('random model loaded for plot')\n",
    "\n",
    "        elif('adaBoost'== mod):\n",
    "            Title='AdaBoost'\n",
    "            m= pd.read_csv(lien+\"plotAdaBoost.csv\",sep=',')\n",
    "            print('AdaBoost loaded for plot')\n",
    "\n",
    "        elif('bagging'== mod):\n",
    "            Title='Bagging'\n",
    "            m= pd.read_csv(lien+\"plotBagging.csv\",sep=',')\n",
    "            print('bagging loaded for plot')\n",
    "            \n",
    "        elif('DT'== mod):\n",
    "            Title='Decision Tree'\n",
    "            m= pd.read_csv(lien+\"plotDT.csv\",sep=',')\n",
    "            print('DT loaded for plot')\n",
    "\n",
    "        elif('mlpACP'== mod):\n",
    "            Title='mlp based on ACP'\n",
    "            m= pd.read_csv(lien+\"plotMlpACP.csv\",sep=',')\n",
    "            print('mlpACP loaded for plot')            \n",
    "            \n",
    "        else: \n",
    "            Title='Naive Bays'\n",
    "            m= pd.read_csv(lien+\"plotBays.csv\",sep=',')\n",
    "            print(' Bays loaded model  for plot')\n",
    "\n",
    "        fp=m.fp\n",
    "        tp=m.tp\n",
    "        AUC= metrics.auc(fp, tp)\n",
    "        lw = 2\n",
    "        trace1 = go.Scatter(x=fp, y=tp, \n",
    "                            mode='lines', \n",
    "                            line=dict(color='darkorange', width=lw),\n",
    "                            name='ROC curve (area = %0.2f)' % AUC )\n",
    "        trace2 = go.Scatter(x=[0, 1], y=[0, 1], \n",
    "                            mode='lines', \n",
    "                            line=dict(color='navy', width=lw, dash='dash'),\n",
    "                            showlegend=False)\n",
    "        layout = go.Layout(title=Title,\n",
    "                            xaxis=dict(title='False Positive Rate'),\n",
    "                            yaxis=dict(title='True Positive Rate'))\n",
    "        print('plot done')\n",
    "        return{ 'data': [trace1, trace2], 'layout': layout }\n",
    "        dcc.Graph(id='multiROC'),\n",
    "#############################################################################################################\n",
    "###### multi roc\n",
    "\n",
    "##########\n",
    "@app.callback(Output('multiROC', 'figure'),\n",
    "              [Input('table', 'rows'),\n",
    "               Input('dropdownX', 'value'),\n",
    "               Input('dropdownY', 'value'),\n",
    "               Input ('selectAll', 'value'),\n",
    "               Input ('subs', 'value'),\n",
    "               Input ('echSplit', 'value'),\n",
    "               Input ('Mroc','n_clicks'),\n",
    "               Input ('Multimodel', 'values'),\n",
    "                #selecte features\n",
    "               Input('tableBestFeat', 'rows'),\n",
    "               Input('selectVar', 'value'),\n",
    "               Input('useSelectedFeature','value')\n",
    "               \n",
    "              ])\n",
    "\n",
    "def MultiROCPlot (tablerows, xvar,yvar, selectAll, subs, ech, button, mod,\n",
    "               tableBestFeat, selectVar, useSelectedFeature):\n",
    "    lw=2\n",
    "    trace = go.Scatter(x=[0, 1], y=[0, 1], \n",
    "                        mode='lines', \n",
    "                        line=dict(color='navy', width=lw, dash='dash'),\n",
    "                        showlegend=False)\n",
    "    layout = go.Layout(title='Compare last generated models',\n",
    "                        xaxis=dict(title='False Positive Rate'),\n",
    "                        yaxis=dict(title='True Positive Rate'))\n",
    "    if (button ==None):\n",
    "        return { 'data': [trace], 'layout': layout }\n",
    "    else:\n",
    "        if ('logreg' in mod): \n",
    "            m= pd.read_csv(lien+\"plotLogreg.csv\",sep=',')\n",
    "            print(' logreg loaded model  for multi  plot')\n",
    "            fp_logreg=m.fp\n",
    "            tp_logreg=m.tp\n",
    "            AUC_logreg= metrics.auc(fp_logreg, tp_logreg)            \n",
    "            trace1 = go.Scatter(x=fp_logreg, y=tp_logreg, \n",
    "                                mode='lines', \n",
    "                                line=dict(color='darkorange', width=lw),\n",
    "                                name='Logreg ROC  curve (area = %0.2f)' % AUC_logreg )\n",
    "        else :  trace1=trace\n",
    "        if ('mlp' in mod): \n",
    "            m= pd.read_csv(lien+\"plotMlp.csv\",sep=',')\n",
    "            fp_mlp=m.fp\n",
    "            tp_mlp=m.tp\n",
    "            AUC_mlp= metrics.auc(fp_mlp, tp_mlp)            \n",
    "            trace2 = go.Scatter(x=fp_mlp, y=tp_mlp, \n",
    "                                mode='lines', \n",
    "                                line=dict(color='orange', width=lw),\n",
    "                                name='MLP ROC curve (area = %0.2f)' % AUC_mlp )\n",
    "        else: trace2=trace\n",
    "        if ('gbm'in mod):\n",
    "            print(' gbm loaded model  for multi  plot')\n",
    "            m= pd.read_csv(lien+\"plotGbm.csv\",sep=',')\n",
    "            fp_gbm=m.fp\n",
    "            tp_gbm=m.tp\n",
    "            AUC_gbm= metrics.auc(fp_gbm, tp_gbm)                        \n",
    "            trace3 = go.Scatter(x=fp_gbm, y=tp_gbm, \n",
    "                                mode='lines', \n",
    "                                line=dict(color='pink', width=lw),\n",
    "                                name=' GBM ROC curve (area = %0.2f)' % AUC_gbm )\n",
    "        else: trace3=trace\n",
    "        if('random' in mod):\n",
    "            m= pd.read_csv(lien+\"plotRandom.csv\",sep=',')\n",
    "            print(' random loaded model  for multi  plot')\n",
    "            fp_random=m.fp\n",
    "            tp_random=m.tp\n",
    "            AUC_random= metrics.auc(fp_random, tp_random)            \n",
    "\n",
    "            trace4 = go.Scatter(x=fp_random, y=tp_random, \n",
    "                                mode='lines', \n",
    "                                line=dict(color='blue', width=lw),\n",
    "                                name='Random forest ROC curve (area = %0.2f)' % AUC_random )\n",
    "        else: trace4=trace\n",
    "        if('adaBoost' in mod):\n",
    "            m= pd.read_csv(lien+\"plotAdaBoost.csv\",sep=',')\n",
    "            print(' adaBoost loaded model  for multi  plot')\n",
    "            fp_adaBoost=m.fp\n",
    "            tp_adaBoost=m.tp\n",
    "            AUC_adaBoost= metrics.auc(fp_adaBoost, tp_adaBoost)            \n",
    "\n",
    "            trace5 = go.Scatter(x=fp_adaBoost, y=tp_adaBoost, \n",
    "                                mode='lines', \n",
    "                                line=dict(color='#ff66d9', width=lw),\n",
    "                                name='AdaBoost forest ROC curve (area = %0.2f)' % AUC_adaBoost )\n",
    "        else: trace5=trace\n",
    "        if('bagging' in mod):\n",
    "            m= pd.read_csv(lien+\"plotBagging.csv\",sep=',')\n",
    "            print(' bagging loaded model  for multi  plot')\n",
    "            fp_bagging=m.fp\n",
    "            tp_bagging=m.tp\n",
    "            AUC_bagging= metrics.auc(fp_bagging, tp_bagging)            \n",
    "\n",
    "            trace6 = go.Scatter(x=fp_bagging, y=tp_bagging, \n",
    "                                mode='lines', \n",
    "                                line=dict(color='#00e600', width=lw),\n",
    "                                name='Bagging forest ROC curve (area = %0.2f)' % AUC_bagging )\n",
    "        else: trace6=trace\n",
    "        if('DT' in mod):\n",
    "            m= pd.read_csv(lien+\"plotDT.csv\",sep=',')\n",
    "            print(' DT loaded model  for multi  plot')\n",
    "            fp_DT=m.fp\n",
    "            tp_DT=m.tp\n",
    "            AUC_DT= metrics.auc(fp_DT, tp_DT)            \n",
    "\n",
    "            trace7 = go.Scatter(x=fp_DT, y=tp_DT, \n",
    "                                mode='lines', \n",
    "                                line=dict(color='#ff3300', width=lw),\n",
    "                                name='DT forest ROC curve (area = %0.2f)' % AUC_DT )\n",
    "        else: trace7=trace\n",
    "        if('mlpACP' in mod):\n",
    "            m= pd.read_csv(lien+\"plotMlpACP.csv\",sep=',')\n",
    "            print(' mlpACP loaded model  for multi  plot')\n",
    "            fp_mlpACP=m.fp\n",
    "            tp_mlpACP=m.tp\n",
    "            AUC_mlpACP= metrics.auc(fp_mlpACP, tp_mlpACP)            \n",
    "\n",
    "            trace8 = go.Scatter(x=fp_mlpACP, y=tp_mlpACP, \n",
    "                                mode='lines', \n",
    "                                line=dict(color='#00cccc', width=lw),\n",
    "                                name='MlpACP forest ROC curve (area = %0.2f)' % AUC_mlpACP )\n",
    "        else: trace8=trace\n",
    "\n",
    "        if ('bays' in mod):\n",
    "            m= pd.read_csv(lien+\"plotBays.csv\",sep=',')\n",
    "            print(' bays loaded model  for multi  plot')\n",
    "            fp_bays=m.fp\n",
    "            tp_bays=m.tp\n",
    "            AUC_bays= metrics.auc(fp_bays, tp_bays)            \n",
    "            trace9 = go.Scatter(x=fp_bays, y=tp_bays, \n",
    "                                mode='lines', \n",
    "                                line=dict(color='deeppink', width=lw),\n",
    "                                name=' Bays ROC curve (area = %0.2f)' % AUC_bays )\n",
    "        else : trace9= trace\n",
    "        \n",
    "        layout = go.Layout(title='Receiver operating characteristic example',\n",
    "                            xaxis=dict(title='False Positive Rate'),\n",
    "                            yaxis=dict(title='True Positive Rate'))\n",
    "        print(' multi plot done')\n",
    "        return{ 'data': [trace1, trace2, trace3, trace4, trace5,trace6,trace7,trace8,trace9, trace], 'layout': layout }\n",
    "    \n",
    "###########################################################################################################\n",
    "### compare table     \n",
    "\n",
    "@app.callback(Output('compareTable', 'rows'),\n",
    "              [\n",
    "               Input ('Mroc','n_clicks'),   \n",
    "               Input ('Multimodel', 'values'),\n",
    "              ])\n",
    "\n",
    "def compareTable (button,mod):\n",
    "\n",
    "    report=pd.DataFrame({'Evaluation metric':['Model','AUC','Accuracy','erreur I','erreurII' ]})\n",
    "    if (button ==None):\n",
    "        return [{}]\n",
    "    else:\n",
    "### log reg        \n",
    "        if ('logreg' in mod): \n",
    "            titre_logreg='Logistic Regression'\n",
    "            m= pd.read_csv(lien+\"plotLogreg.csv\",sep=',')\n",
    "            fp_logreg=m.fp\n",
    "            tp_logreg=m.tp\n",
    "            AUC_logreg= metrics.auc(fp_logreg, tp_logreg)\n",
    "            m= pd.read_csv(lien+\"CMlogreg.csv\",sep=',')\n",
    "            data={titre_logreg:['actuel 0','actuel 1'],'predicted 0':[m.iloc[0]['0'],m.iloc[1]['0'] ], 'predicted 1':[m.iloc[0]['1'],m.iloc[1]['1'] ] }\n",
    "            TN= m.iloc[0]['0']   \n",
    "            FP=m.iloc[0]['1']\n",
    "            FN=m.iloc[1]['0']\n",
    "            TP=m.iloc[1]['1']\n",
    "            ## accuracy\n",
    "            model_score_logreg =(TP+TN)/(TP+TN+FP+FN)\n",
    "            #false negative rate error type I \n",
    "            fnr_logreg=FN/(FN+ TP)\n",
    "            #False negaive rate error type II\n",
    "            fpr_logreg=FP/(FP+TN)\n",
    "            report[titre_logreg]=[titre_logreg,AUC_logreg,model_score_logreg,fnr_logreg,fpr_logreg]\n",
    "            print('compare table logreg done ')\n",
    "        if ('gbm' in mod): \n",
    "            titre_gbm='Gradient Boosting'\n",
    "            m= pd.read_csv(lien+\"plotGbm.csv\",sep=',')\n",
    "            fp_gbm=m.fp\n",
    "            tp_gbm=m.tp\n",
    "            AUC_gbm= metrics.auc(fp_gbm, tp_gbm)\n",
    "            m= pd.read_csv(lien+\"CMgbm.csv\",sep=',')\n",
    "            data={titre_gbm:['actuel 0','actuel 1'],'predicted 0':[m.iloc[0]['0'],m.iloc[1]['0'] ], 'predicted 1':[m.iloc[0]['1'],m.iloc[1]['1'] ] }\n",
    "            TN= m.iloc[0]['0']   \n",
    "            FP=m.iloc[0]['1']\n",
    "            FN=m.iloc[1]['0']\n",
    "            TP=m.iloc[1]['1']\n",
    "            ## accuracy\n",
    "            model_score_gbm =(TP+TN)/(TP+TN+FP+FN)\n",
    "            #false negative rate error type I \n",
    "            fnr_gbm=FN/(FN+ TP)\n",
    "            #False negaive rate error type II\n",
    "            fpr_gbm=FP/(FP+TN)\n",
    "            report[titre_gbm]=[titre_gbm,AUC_gbm,model_score_gbm,fnr_gbm,fpr_gbm]\n",
    "            print('compare table gbm done ')\n",
    "\n",
    "        if ('DT' in mod): \n",
    "            titre_DT='Decision Tree'\n",
    "            m= pd.read_csv(lien+\"plotDT.csv\",sep=',')\n",
    "            fp_DT=m.fp\n",
    "            tp_DT=m.tp\n",
    "            AUC_DT= metrics.auc(fp_DT, tp_DT)\n",
    "\n",
    "            m= pd.read_csv(lien+\"CMDT.csv\",sep=',')\n",
    "            data={titre_DT:['actuel 0','actuel 1'],'predicted 0':[m.iloc[0]['0'],m.iloc[1]['0'] ], 'predicted 1':[m.iloc[0]['1'],m.iloc[1]['1'] ] }\n",
    "            TN= m.iloc[0]['0']   \n",
    "            FP=m.iloc[0]['1']\n",
    "            FN=m.iloc[1]['0']\n",
    "            TP=m.iloc[1]['1']\n",
    "            ## accuracy\n",
    "            model_score_DT =(TP+TN)/(TP+TN+FP+FN)\n",
    "            #false negative rate error type I \n",
    "            fnr_DT=FN/(FN+ TP)\n",
    "            #False negaive rate error type II\n",
    "            fpr_DT=FP/(FP+TN)\n",
    "            report[titre_DT]=[titre_DT,AUC_DT,model_score_DT,fnr_DT,fpr_DT]\n",
    "        if ('adaBoost' in mod): \n",
    "            titre_adaBoost='AdaBoost Tree'\n",
    "            m= pd.read_csv(lien+\"plotAdaBoost.csv\",sep=',')\n",
    "            fp_adaBoost=m.fp\n",
    "            tp_adaBoost=m.tp\n",
    "            AUC_adaBoost= metrics.auc(fp_adaBoost, tp_adaBoost)\n",
    "            m= pd.read_csv(lien+\"CMadaBoost.csv\",sep=',')\n",
    "            data={titre_adaBoost:['actuel 0','actuel 1'],'predicted 0':[m.iloc[0]['0'],m.iloc[1]['0'] ], 'predicted 1':[m.iloc[0]['1'],m.iloc[1]['1'] ] }\n",
    "            TN= m.iloc[0]['0']   \n",
    "            FP=m.iloc[0]['1']\n",
    "            FN=m.iloc[1]['0']\n",
    "            TP=m.iloc[1]['1']\n",
    "            ## accuracy\n",
    "            model_score_adaBoost =(TP+TN)/(TP+TN+FP+FN)\n",
    "            #false negative rate error type I \n",
    "            fnr_adaBoost=FN/(FN+ TP)\n",
    "            #False negaive rate error type II\n",
    "            fpr_adaBoost=FP/(FP+TN)\n",
    "            report[titre_adaBoost]=[titre_adaBoost,AUC_adaBoost,model_score_adaBoost,fnr_adaBoost,fpr_adaBoost]\n",
    "        if ('random' in mod): \n",
    "            titre_random='Random Forest'\n",
    "            m= pd.read_csv(lien+\"plotRandom.csv\",sep=',')\n",
    "            fp_random=m.fp\n",
    "            tp_random=m.tp\n",
    "            AUC_random= metrics.auc(fp_random, tp_random)\n",
    "            m= pd.read_csv(lien+\"CMrandom.csv\",sep=',')\n",
    "            data={titre_random:['actuel 0','actuel 1'],'predicted 0':[m.iloc[0]['0'],m.iloc[1]['0'] ], 'predicted 1':[m.iloc[0]['1'],m.iloc[1]['1'] ] }\n",
    "            TN= m.iloc[0]['0']   \n",
    "            FP=m.iloc[0]['1']\n",
    "            FN=m.iloc[1]['0']\n",
    "            TP=m.iloc[1]['1']\n",
    "            ## accuracy\n",
    "            model_score_random =(TP+TN)/(TP+TN+FP+FN)\n",
    "            #false negative rate error type I \n",
    "            fnr_random=FN/(FN+ TP)\n",
    "            #False negaive rate error type II\n",
    "            fpr_random=FP/(FP+TN)\n",
    "            report[titre_random]=[titre_random,AUC_random,model_score_random,fnr_random,fpr_random]\n",
    "        if ('bagging' in mod): \n",
    "            titre_bagging='Bagging Tree'\n",
    "            m= pd.read_csv(lien+\"plotBagging.csv\",sep=',')\n",
    "            fp_bagging=m.fp\n",
    "            tp_bagging=m.tp\n",
    "            AUC_bagging= metrics.auc(fp_bagging, tp_bagging)\n",
    "            m= pd.read_csv(lien+\"CMbagging.csv\",sep=',')\n",
    "            data={titre_bagging:['actuel 0','actuel 1'],'predicted 0':[m.iloc[0]['0'],m.iloc[1]['0'] ], 'predicted 1':[m.iloc[0]['1'],m.iloc[1]['1'] ] }\n",
    "            TN= m.iloc[0]['0']   \n",
    "            FP=m.iloc[0]['1']\n",
    "            FN=m.iloc[1]['0']\n",
    "            TP=m.iloc[1]['1']\n",
    "            ## accuracy\n",
    "            model_score_bagging =(TP+TN)/(TP+TN+FP+FN)\n",
    "            #false negative rate error type I \n",
    "            fnr_bagging=FN/(FN+ TP)\n",
    "            #False negaive rate error type II\n",
    "            fpr_bagging=FP/(FP+TN)\n",
    "            report[titre_bagging]=[titre_bagging,AUC_bagging,model_score_bagging,fnr_bagging,fpr_bagging]\n",
    "        if ('mlp' in mod): \n",
    "            titre_mlp='ML Perceptrons'\n",
    "            m= pd.read_csv(lien+\"plotMlp.csv\",sep=',')\n",
    "            fp_mlp=m.fp\n",
    "            tp_mlp=m.tp\n",
    "            AUC_mlp= metrics.auc(fp_mlp, tp_mlp)\n",
    "            m= pd.read_csv(lien+\"CMmlp.csv\",sep=',')\n",
    "            data={titre_mlp:['actuel 0','actuel 1'],'predicted 0':[m.iloc[0]['0'],m.iloc[1]['0'] ], 'predicted 1':[m.iloc[0]['1'],m.iloc[1]['1'] ] }\n",
    "            TN= m.iloc[0]['0']   \n",
    "            FP=m.iloc[0]['1']\n",
    "            FN=m.iloc[1]['0']\n",
    "            TP=m.iloc[1]['1']\n",
    "            ## accuracy\n",
    "            model_score_mlp =(TP+TN)/(TP+TN+FP+FN)\n",
    "            #false negative rate error type I \n",
    "            fnr_mlp=FN/(FN+ TP)\n",
    "            #False negaive rate error type II\n",
    "            fpr_mlp=FP/(FP+TN)\n",
    "            report[titre_mlp]=[titre_mlp,AUC_mlp,model_score_mlp,fnr_mlp,fpr_mlp]\n",
    "        if ('mlpACP' in mod): \n",
    "            titre_mlpACP='ML Perceptrons ACP'\n",
    "            m= pd.read_csv(lien+\"plotMlpACP.csv\",sep=',')\n",
    "            fp_mlpACP=m.fp\n",
    "            tp_mlpACP=m.tp\n",
    "            AUC_mlpACP= metrics.auc(fp_mlpACP, tp_mlpACP)\n",
    "            m= pd.read_csv(lien+\"CMmlpACP.csv\",sep=',')\n",
    "            data={titre_mlpACP:['actuel 0','actuel 1'],'predicted 0':[m.iloc[0]['0'],m.iloc[1]['0'] ], 'predicted 1':[m.iloc[0]['1'],m.iloc[1]['1'] ] }\n",
    "            TN= m.iloc[0]['0']   \n",
    "            FP=m.iloc[0]['1']\n",
    "            FN=m.iloc[1]['0']\n",
    "            TP=m.iloc[1]['1']\n",
    "            ## accuracy\n",
    "            model_score_mlpACP =(TP+TN)/(TP+TN+FP+FN)\n",
    "            #false negative rate error type I \n",
    "            fnr_mlpACP=FN/(FN+ TP)\n",
    "            #False negaive rate error type II\n",
    "            fpr_mlpACP=FP/(FP+TN)\n",
    "            report[titre_mlpACP]=[titre_mlpACP,AUC_mlpACP,model_score_mlpACP,fnr_mlpACP,fpr_mlpACP]\n",
    "        if ('bays' in mod): \n",
    "            titre_bays='bays'\n",
    "            m= pd.read_csv(lien+\"plotBays.csv\",sep=',')\n",
    "            fp_bays=m.fp\n",
    "            tp_bays=m.tp\n",
    "            AUC_bays= metrics.auc(fp_bays, tp_bays)\n",
    "            m= pd.read_csv(lien+\"CMbays.csv\",sep=',')\n",
    "            data={titre_bays:['actuel 0','actuel 1'],'predicted 0':[m.iloc[0]['0'],m.iloc[1]['0'] ], 'predicted 1':[m.iloc[0]['1'],m.iloc[1]['1'] ] }\n",
    "            TN= m.iloc[0]['0']   \n",
    "            FP=m.iloc[0]['1']\n",
    "            FN=m.iloc[1]['0']\n",
    "            TP=m.iloc[1]['1']\n",
    "            ## accuracy\n",
    "            model_score_bays =(TP+TN)/(TP+TN+FP+FN)\n",
    "            #false negative rate error type I \n",
    "            fnr_bays=FN/(FN+ TP)\n",
    "            #False negaive rate error type II\n",
    "            fpr_bays=FP/(FP+TN)\n",
    "            report[titre_bays]=[titre_bays,AUC_bays,model_score_bays,fnr_bays,fpr_bays]\n",
    "            print('compare table  bays added')\n",
    "            \n",
    "\n",
    "\n",
    "       \n",
    "        ###\n",
    "        return  report.to_dict('records')    \n",
    "\n",
    "###########################################################################################################\n",
    "########### make a prediction \n",
    "@app.callback(Output('predict', 'rows'),\n",
    "              [Input('upload_pred', 'contents'),\n",
    "               Input('upload_pred', 'filename'),\n",
    "               Input('dropdownY', 'value'),\n",
    "               Input('dropdownX','value'),\n",
    "               Input ('subs', 'value'),\n",
    "               Input ('model', 'value'),\n",
    "               Input ('selectAll', 'value'),\n",
    "                #selecte features\n",
    "               Input('tableBestFeat', 'rows'),\n",
    "               Input('selectVar', 'value'),\n",
    "               Input('useSelectedFeature','value')\n",
    "               \n",
    "              ])\n",
    "def predict_output(contents, filename,yvar,xvar, subs,mod, selectAll,\n",
    "               tableBestFeat, selectVar, useSelectedFeature):\n",
    "    if contents is not None:\n",
    "        df = parse_contents(contents, filename)\n",
    "        if df is not None:\n",
    "            ####\n",
    "            if (useSelectedFeature== 'yes'):\n",
    "                print('you choosed to work with selected features')    \n",
    "                tableBestFeat=pd.DataFrame(tableBestFeat)\n",
    "                if (selectVar=='RFE'):\n",
    "                    Features=tableBestFeat.loc[tableBestFeat['Selected'] == 'TRUE']['Features']\n",
    "                    x=df[Features]\n",
    "                    print('REF var loaded successfully')\n",
    "                else:\n",
    "                    Features=tableBestFeat['*'].tolist()\n",
    "                    x=df[Features]\n",
    "                    print('corr deleted var loaded successfully')\n",
    "            else: \n",
    "                print('you dicided to work with the inatial var')\n",
    "                if (selectAll== 'all') :\n",
    "                    x=df.drop([subs], axis=1)\n",
    "                    print(' all var loaded  to compute prediction')\n",
    "                else : \n",
    "                    x=df[xvar]\n",
    "                    print('not all var loaded  to compute prediction')\n",
    "\n",
    "            if('logreg'== mod):\n",
    "                with open(\"python_logreg_model.pkl\", \"rb\") as file_handler:\n",
    "                    model = joblib.load(file_handler)\n",
    "                print('Logistic reg model loaded for prediction')\n",
    "\n",
    "            elif('mlp'== mod):\n",
    "                with open(\"python_mlp_model.pkl\", \"rb\") as file_handler:\n",
    "                    model = joblib.load(file_handler)\n",
    "                print('mlp model loaded for prediction')\n",
    "\n",
    "            elif('gbm'== mod):\n",
    "                with open(\"python_gbm_model.pkl\", \"rb\") as file_handler:\n",
    "                    model = joblib.load(file_handler)\n",
    "                print('gbm model loaded for prediction')\n",
    "\n",
    "            elif('random'== mod):\n",
    "                with open(\"python_random_model.pkl\", \"rb\") as file_handler:\n",
    "                    model = joblib.load(file_handler)\n",
    "                print('random model loaded for prediction')\n",
    "\n",
    "\n",
    "            else: \n",
    "                with open(\"python_bays_model.pkl\", \"rb\") as file_handler:\n",
    "                    model = joblib.load(file_handler)\n",
    "                print(' Bays loaded model  for prediction')\n",
    "            \n",
    "            ####\n",
    "\n",
    "            pre=pd.DataFrame(model.predict(x))\n",
    "            p=pd.concat([pre,df[subs]],axis=1 )\n",
    "            print('prediction done')\n",
    "            return p.to_dict('records')            \n",
    "        else:\n",
    "            return [{}]\n",
    "    else:\n",
    "        return [{}]\n",
    "#######\n",
    "@app.callback( Output('downloadResult', 'children'),\n",
    "              [ Input('predict','rows'),\n",
    "                Input('download', 'n_clicks')],\n",
    "                [dash.dependencies.State('url','value')]\n",
    "               \n",
    "              )\n",
    "def downloadTbale(table, button, url):\n",
    "    if (button ==0) : \n",
    "        return [{}]\n",
    "    else:\n",
    "        fileName=str(url)+'/predict.csv'\n",
    "        table=pd.DataFrame(table)\n",
    "        table.to_csv(fileName, sep=';', encoding='utf-8')\n",
    "        return 'Prediction table has been dowloadded successfully in : \"{}\"' .format(fileName)\n",
    "\n",
    "\n",
    "    \n",
    "app.css.append_css({\n",
    "    \"external_url\": \"https://codepen.io/chriddyp/pen/bWLwgP.css\"\n",
    "})\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run_server(debug=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
